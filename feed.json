{
    "version": "https://jsonfeed.org/version/1",
    "title": "Hexbee&#x27;s Dev Journal",
    "description": "",
    "home_page_url": "https://xav.github.io",
    "feed_url": "https://xav.github.io/feed.json",
    "user_comment": "",
    "icon": "https://xav.github.io/media/website/Logo-SideName.png",
    "author": {
        "name": "Xavier Basty Kjellberg"
    },
    "items": [
        {
            "id": "https://xav.github.io/12-wgsl-fundamentals-data-types-and-variables-2/",
            "url": "https://xav.github.io/12-wgsl-fundamentals-data-types-and-variables-2/",
            "title": "1.2 - WGSL Fundamentals - Data Types &amp; Variables",
            "summary": "What We’re Learning In our last article, we built a mental model of the graphics pipeline: a VFX studio where “Layout Artists” (Vertex Shaders) position&hellip;",
            "content_html": "<h2 id=\"what-were-learning\">What We’re Learning</h2>\n<p>In our last article, we built a mental model of the graphics pipeline: a VFX studio where “Layout Artists” (Vertex Shaders) position geometry and “Coloring Artists” (Fragment Shaders) paint the final pixels. But what materials do these artists work with? How do we hand them a 3D coordinate to transform, a surface direction for lighting, or a final color to paint? How do we describe the data that flows through their assembly line?</p><p>This is where WGSL’s data types come in. These aren’t generic programming types; they are the fundamental vocabulary of the GPU - the digital clay, paint, and transformation tools our artists use to build a visual world. Learning them is like learning the alphabet before you can write a story.</p><p>At the lowest level, we have <strong>scalar</strong> types - the individual numbers that form the atoms of our data. But the real power comes from combining these into <strong>vectors</strong>, the workhorse of every shader, representing everything from a <code>vec3&lt;f32&gt;</code> position to a <code>vec4&lt;f32&gt;</code> RGBA color. And to manipulate these vectors - to move, rotate, and project them - we use <strong>matrices</strong>, the mathematical machines of transformation.</p><p>By the end of this article, you’ll understand:</p><ul>\n<li>The atomic building blocks of all shader data: <code>f32</code>, <code>i32</code>, <code>u32</code>, and <code>bool</code>.</li>\n<li>The workhorse of all shaders: how <strong>vectors</strong> (<code>vec2</code>, <code>vec3</code>, <code>vec4</code>) represent everything from 3D positions to RGBA colors.</li>\n<li>The language of transformation: how <strong>matrices</strong> (<code>mat4x4</code>) are the machines that move, rotate, and scale your geometry.</li>\n<li>The crucial difference between an immutable <code>let</code> (a constant) and a mutable <code>var</code> (a variable), and why you should almost always prefer <code>let</code>.</li>\n<li>Powerful GPU-native shortcuts like <strong>constructors</strong> for building vectors and <strong>swizzling</strong> for efficiently accessing and rearranging their components.</li>\n</ul>\n<h2 id=\"scalar-types-the-basics\">Scalar Types: The Basics</h2>\n<p>At the heart of all shader calculations are <strong>scalar</strong> types. A scalar is simply a single value, like one number or a boolean state. WGSL provides four fundamental scalar types that serve as the atoms for all the more complex data we will build.</p><h3 id=\"floating-point-numbers-f32\">Floating-Point Numbers: <code>f32</code></h3>\n<p>This is the single most important type in WGSL and your absolute workhorse for graphics programming. It represents a 32-bit floating-point number, which is essential for describing any data that is continuous and requires precision.</p><pre><code class=\"language-wgsl\">let pi: f32 = 3.14159;\nlet half: f32 = 0.5;\nlet negative_one_point_five: f32 = -1.5;\n</code></pre>\n<p><strong>Key Rule:</strong> WGSL is very strict about types. A number literal without a decimal point is treated as an integer. To create an <code>f32</code>, you <strong>must</strong> include a decimal point, even for whole numbers.</p><pre><code class=\"language-wgsl\">let correct_float: f32 = 1.0; // ✓ Correct, this is a float.\nlet wrong: f32 = 1;           // ✗ COMPILE ERROR: Cannot assign an integer to an f32.\n</code></pre>\n<p>You will use <code>f32</code> for almost everything, including:</p><ul>\n<li>Positions (X, Y, Z coordinates)</li>\n<li>Colors (R, G, B channels)</li>\n<li>Texture Coordinates (U, V)</li>\n<li>Time, opacity, and any fractional value</li>\n</ul>\n<h3 id=\"signed-integers-i32\">Signed Integers: <code>i32</code></h3>\n<p>This is a standard 32-bit signed integer, meaning it can represent both positive and negative whole numbers.</p><pre><code class=\"language-wgsl\">let count: i32 = 42;\nlet negative_ten: i32 = -10;\nlet zero: i32 = 0;\n</code></pre>\n<p>Use <code>i32</code> when you need whole numbers and the possibility of a negative value is meaningful, such as for:</p><ul>\n<li>Loop counters that might count down</li>\n<li>Calculations involving differences or offsets</li>\n<li>Bitwise operations</li>\n</ul>\n<h3 id=\"unsigned-integers-u32\">Unsigned Integers: <code>u32</code></h3>\n<p>This is a 32-bit unsigned integer, meaning it can only represent non-negative whole numbers (zero and positive values).</p><pre><code class=\"language-wgsl\">let index: u32 = 0u;\nlet size: u32 = 256u;\n</code></pre>\n<p><strong>Key Rule:</strong> To distinguish an unsigned integer literal from a signed one, you <strong>must</strong> add a <code>u</code> suffix.</p><p>Use u32 when a value can never logically be negative. This is both a safety feature and a way to signal intent. Common uses include:</p><ul>\n<li>Array indices and lengths</li>\n<li>Bevy’s <code>@builtin(instance_index)</code></li>\n<li>Identifiers or flags packed into an integer</li>\n</ul>\n<h3 id=\"booleans-bool\">Booleans: <code>bool</code></h3>\n<p>The <code>bool</code> type represents a simple <code>true</code> or <code>false</code> value.</p><pre><code class=\"language-wgsl\">let is_visible: bool = true;\nlet has_texture: bool = false;\n</code></pre>\n<p>Booleans are the foundation of all logic and control flow in your shaders. You’ll use them for:</p><ul>\n<li><code>if/else</code> statements and other conditional logic</li>\n<li>Storing the result of a comparison (e.g., <code>let is_close = distance &lt; 1.0;</code>)</li>\n<li>Flags passed in from your Rust code to enable or disable shader features</li>\n</ul>\n<h2 id=\"vector-types-your-new-best-friends\">Vector Types: Your New Best Friends</h2>\n<p>If scalars are the atoms of our data, <strong>vectors</strong> are the molecules. They are the heart and soul of shader programming. A vector is an ordered collection of scalars, but in graphics, it’s a powerful tool for representing multi-dimensional data like positions, colors, and directions.</p><p>The GPU is a parallel processing beast. It is specifically designed to perform the same mathematical operation on large batches of data all at once. Vectors are the native language of this architecture. When you add two <code>vec3</code> values together, the GPU can perform all three additions (x+x, y+y, z+z) simultaneously. Using vectors effectively is the key to unlocking the GPU’s performance and writing elegant shader code.</p><h3 id=\"vector-syntax\">Vector Syntax</h3>\n<p>WGSL defines vectors with a simple, clear syntax: <code>vecN&lt;T&gt;</code>, where <code>N</code> is the number of components (2, 3, or 4) and <code>T</code> is the scalar type of those components. While you can create vectors of any scalar type, floating-point vectors are used in over 99% of graphics operations.</p><table>\n<thead>\n<tr>\n<th>Type</th>\n<th>Common Usage</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>vec2&lt;f32&gt;</code></td>\n<td>2D positions, and especially texture coordinates (UVs).</td>\n</tr>\n<tr>\n<td><code>vec3&lt;f32&gt;</code></td>\n<td>The workhorse for 3D graphics: 3D positions, RGB colors, surface normals, direction vectors.</td>\n</tr>\n<tr>\n<td><code>vec4&lt;f32&gt;</code></td>\n<td>RGBA colors (with an alpha channel for transparency) and homogeneous coordinates, such as the final clip-space position from a vertex shader.</td>\n</tr>\n<tr>\n<td><code>vec2&lt;i32&gt;</code></td>\n<td>Less common, but useful for things like integer grid coordinates or texture dimensions in pixels.</td>\n</tr>\n</tbody></table>\n<h3 id=\"creating-vectors-constructors\">Creating Vectors (Constructors)</h3>\n<p>WGSL provides a flexible set of “constructors” to build vectors in whatever way is most convenient. This lets you write clean, readable code without needing to manually handle every single component.</p><pre><code class=\"language-wgsl\">// 1. From individual scalar components: The most direct method.\nlet pos = vec3&lt;f32&gt;(1.0, 2.0, 3.0);\nlet red = vec4&lt;f32&gt;(1.0, 0.0, 0.0, 1.0); // Red with full alpha\n\n// 2. From a single value (a &quot;splat&quot;): A useful shortcut.\n// This creates a vector where all components have the same value.\nlet gray = vec3&lt;f32&gt;(0.5); // Equivalent to vec3&lt;f32&gt;(0.5, 0.5, 0.5)\n\n// 3. Combining smaller vectors and scalars: Extremely common and powerful.\n// The components are simply concatenated in order to form the new vector.\nlet xy = vec2&lt;f32&gt;(1.0, 2.0);\nlet xyz = vec3&lt;f32&gt;(xy, 3.0);       // -&gt; Creates vec3(1.0, 2.0, 3.0)\nlet xyzw = vec4&lt;f32&gt;(xy, 3.0, 4.0); // -&gt; Creates vec4(1.0, 2.0, 3.0, 4.0)\n\n// 4. From another vector and a scalar: The classic way to add a dimension.\n// A common example is adding an alpha channel to an existing RGB color.\nlet rgb_color = vec3&lt;f32&gt;(1.0, 0.5, 0.0); // An orange color\nlet rgba_color = vec4&lt;f32&gt;(rgb_color, 1.0); // -&gt; Creates vec4(1.0, 0.5, 0.0, 1.0)\n</code></pre>\n<h3 id=\"accessing-vector-components\">Accessing Vector Components</h3>\n<p>To work with vectors, you need to access their individual components. WGSL gives you several accessor “schemes” which are aliases for each other. Using the right scheme is a best practice that makes your code much more readable by signaling your intent.</p><pre><code class=\"language-wgsl\">let my_vector = vec4&lt;f32&gt;(1.0, 0.5, 0.0, 1.0);\n\n// The &quot;spatial&quot; or &quot;geometric&quot; scheme: x, y, z, w\n// Use this when the vector represents a position, direction, or texture coordinate.\nlet x_pos = my_vector.x; // 1.0\n\n// The &quot;color&quot; scheme: r, g, b, a\n// Use this when the vector represents a color. This makes the code self-documenting.\nlet green_channel = my_vector.g; // 0.5\n\n// By index (0-based array-style access)\n// This is less common for direct access but is useful for programmatic access,\n// for instance, if you were iterating through a vector&#39;s components in a loop.\nlet first_component = my_vector[0]; // 1.0\n</code></pre>\n<h3 id=\"vector-swizzling-a-gpu-superpower\">Vector Swizzling: A GPU Superpower</h3>\n<p>“Swizzling” is a powerful and highly efficient GPU feature that lets you create a new vector by rearranging, duplicating, or selecting components from an existing vector. It’s not just a syntax shortcut; it compiles to a single, incredibly fast hardware instruction.</p><pre><code class=\"language-wgsl\">let color = vec4&lt;f32&gt;(1.0, 0.5, 0.0, 1.0); // A bright orange color\n\n// 1. Extract a subset of components\n// A very common use is to get the RGB part of an RGBA color.\nlet rgb = color.rgb; // -&gt; Creates a new vec3&lt;f32&gt; with (1.0, 0.5, 0.0)\nlet rg = color.rg;   // -&gt; Creates a new vec2&lt;f32&gt; with (1.0, 0.5)\n\n// 2. Reorder components\n// Useful for converting between different data layouts (e.g., from an image format).\nlet bgr = color.bgr; // -&gt; Creates vec3(0.0, 0.5, 1.0). The components are reversed!\n\n// 3. Duplicate components\n// A great way to create grayscale values or fill a vector from a single channel.\nlet grayscale_from_red = color.rrr; // -&gt; Creates vec3(1.0, 1.0, 1.0)\n\n// 4. Mix and match to build new vectors\n// This is where swizzling shines for geometric operations.\nlet pos = vec3&lt;f32&gt;(1.0, 2.0, 3.0);\nlet yxz = pos.yxz; // -&gt; Creates vec3(2.0, 1.0, 3.0)\n\n// A classic use case: using the X and Z components of a 3D position\n// for 2D calculations, like looking up a texture for a ground plane.\nlet ground_coords = pos.xz; // -&gt; Creates vec2(1.0, 3.0)\n</code></pre>\n<p>You can use the accessor schemes <code>xyzw</code>, <code>rgba</code>, or <code>stpq</code> (a convention for texture coordinates) for swizzling. They all access the same underlying components (0, 1, 2, 3), but you <strong>cannot mix schemes</strong> in a single swizzle (e.g., <code>color.xb</code> is illegal).</p><h3 id=\"vector-arithmetic\">Vector Arithmetic</h3>\n<p>Arithmetic operations on vectors are performed <strong>component-wise</strong>. This means the operation is applied independently to each pair of corresponding components. This is a fundamental concept for everything from blending colors to manipulating positions.</p><pre><code class=\"language-wgsl\">let a = vec3&lt;f32&gt;(1.0, 2.0, 3.0);\nlet b = vec3&lt;f32&gt;(4.0, 5.0, 6.0);\n\n// Addition: result.x = a.x + b.x, result.y = a.y + b.y, etc.\n// Use case: Combining light sources, offsetting a position.\nlet sum = a + b; // -&gt; Result: vec3(5.0, 7.0, 9.0)\n\n// Subtraction: result.x = a.x - b.x, etc.\n// Use case: Finding the direction vector from point A to point B (B - A).\nlet diff = b - a; // -&gt; Result: vec3(3.0, 3.0, 3.0)\n\n// Multiplication (component-wise!): result.x = a.x * b.x, etc.\n// Use case: Tinting. Multiplying a base color by a texture color.\nlet product = a * b; // -&gt; Result: vec3(4.0, 10.0, 18.0)\n\n// Operations with a scalar: The scalar is applied to every component.\n// Use case: Uniform scaling an object or changing the brightness of a color.\nlet scaled_up = a * 2.0;   // -&gt; Result: vec3(2.0, 4.0, 6.0)\nlet scaled_down = b / 2.0; // -&gt; Result: vec3(2.0, 2.5, 3.0)\n</code></pre>\n<p><strong>CRITICAL:</strong> Standard vector multiplication (<code>*</code>) is <strong>component-wise multiplication</strong>, often called the <a href=\"https://en.wikipedia.org/wiki/Hadamard_product_(matrices)\">Hadamard product</a>. It is <strong>NOT</strong> a dot product or a cross product! WGSL provides separate built-in functions (<code>dot()</code>, <code>cross()</code>) for those, which we will cover in a later article. This is one of the most common points of confusion for beginners.</p><h2 id=\"matrix-types-for-transformations\">Matrix Types: For Transformations</h2>\n<p>If vectors represent points and directions, then a <strong>matrix</strong> is the machine that transforms them. Matrices are the mathematical tool we use to perform all the essential 3D operations we discussed in the graphics pipeline: moving (translation), rotating, and scaling objects. They are the engine that powers the journey of a vertex through different coordinate spaces.</p><p>A matrix is a grid of numbers arranged in columns and rows. In WGSL, the syntax is <code>matCxR&lt;T&gt;</code>, where <code>C</code> is the number of columns, <code>R</code> is the number of rows, and <code>T</code> is the scalar type (almost always <code>f32</code>).</p><h3 id=\"common-matrix-types\">Common Matrix Types</h3>\n<p>While various sizes exist, you will primarily work with <code>mat4x4&lt;f32&gt;</code> in 3D graphics.</p><table>\n<thead>\n<tr>\n<th>Type</th>\n<th>Common Usage</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>mat4x4&lt;f32&gt;</code></td>\n<td>The cornerstone of 3D graphics. A single 4x4 matrix can store a combination of translation, rotation, and scale for a 3D object. Bevy’s Model, View, and Projection matrices are all of this type.</td>\n</tr>\n<tr>\n<td><code>mat3x3&lt;f32&gt;</code></td>\n<td>Often used for transforming 3D direction vectors like normals, where translation information should be ignored.</td>\n</tr>\n<tr>\n<td><code>mat2x2&lt;f32&gt;</code></td>\n<td>Used for 2D transformations, for example, rotating or scaling UV coordinates in a fragment shader.</td>\n</tr>\n</tbody></table>\n<p>In your Bevy shaders, you’ll mostly receive <code>mat4x4&lt;f32&gt;</code> matrices from the engine and use them to transform your vertex positions.</p><h3 id=\"creating-matrices-and-column-major-order\">Creating Matrices and Column-Major Order</h3>\n<p>You will rarely build transformation matrices from scratch inside a shader - Bevy’s <code>Transform</code> component does that complex work for you on the CPU. However, it’s crucial to understand how they are constructed. The constructor takes the values for each <strong>column</strong>, one after the other.</p><p><strong>Key Concept:</strong> WGSL matrices, like those in most modern graphics APIs, are <strong>column-major</strong>. This defines how the numbers you provide are stored in memory. It means you provide all the data for the first column, then all for the second, and so on.</p><p>Think of it as filling the matrix grid vertically, one column at a time:</p><pre><code class=\"language-wgsl\">// A 4x4 identity matrix (which represents &quot;no transformation&quot;).\nlet identity = mat4x4&lt;f32&gt;(\n//  Col 0     Col 1     Col 2     Col 3\n    1.0, 0.0, 0.0, 0.0,  // Row 0\n    0.0, 1.0, 0.0, 0.0,  // Row 1\n    0.0, 0.0, 1.0, 0.0,  // Row 2\n    0.0, 0.0, 0.0, 1.0   // Row 3\n);\n\n// This is wrong! The constructor takes columns, not rows.\n// let wrong = mat4x4&lt;f32&gt;(row0, row1, row2, row3); // ✗\n\n// You can also construct a matrix from column vectors. This is often clearer.\nlet col0 = vec4&lt;f32&gt;(1.0, 0.0, 0.0, 0.0);\nlet col1 = vec4&lt;f32&gt;(0.0, 1.0, 0.0, 0.0);\nlet col2 = vec4&lt;f32&gt;(0.0, 0.0, 1.0, 0.0);\nlet col3 = vec4&lt;f32&gt;(0.0, 0.0, 0.0, 1.0);\nlet from_vectors = mat4x4&lt;f32&gt;(col0, col1, col2, col3);\n</code></pre>\n<h3 id=\"accessing-matrix-elements\">Accessing Matrix Elements</h3>\n<p>Accessing matrix data follows this column-major logic. The most important rule to remember is: <strong>column-first, then row</strong>.</p><pre><code class=\"language-wgsl\">let m = ... // some mat4x4&lt;f32&gt;\n\n// Get an entire column as a vector\nlet second_column: vec4&lt;f32&gt; = m[1]; // Index 1 gives you the second column.\n\n// Access a specific element: matrix[column_index][row_index]\nlet element_c1_r2 = m[1][2]; // Get the element in Column 1, Row 2.\n</code></pre>\n<h3 id=\"the-magic-matrix-vector-multiplication\">The Magic: Matrix-Vector Multiplication</h3>\n<p>The real power of a matrix is revealed when you multiply it by a vector. This operation <strong>applies the transformation</strong> stored in the matrix to the vector, producing a new, transformed vector.</p><p>This is <strong>NOT</strong> component-wise multiplication! It’s a special mathematical operation that correctly rotates, scales, and translates the vector. We will dive deep into the math in a later article. For now, just focus on the syntax and the result.</p><pre><code class=\"language-wgsl\">// Conceptual vertex shader code\n// These matrices are provided by Bevy&#39;s renderer.\nlet model_matrix: mat4x4&lt;f32&gt; = ...;\nlet view_matrix: mat4x4&lt;f32&gt; = ...;\nlet projection_matrix: mat4x4&lt;f32&gt; = ...;\n\n// The original vertex position from the mesh.\n// We use a vec4 with w=1.0 for positions so that translation works correctly.\nlet local_position = vec4&lt;f32&gt;(1.0, 2.0, 3.0, 1.0);\n\n// Apply the transformations in sequence.\n// Note the order: Projection * View * Model * Position\nlet world_position = model_matrix * local_position;\nlet view_position = view_matrix * world_position;\nlet clip_position = projection_matrix * view_position;\n</code></pre>\n<p>This sequence of multiplications is the absolute core of every 3D vertex shader. It’s the code that executes the “Coordinate Space Journey” we learned about previously, taking a vertex from its local blueprint all the way to its final place on the screen.</p><h2 id=\"variables-var-vs-let\">Variables: <code>var</code> vs <code>let</code></h2>\n<p>WGSL provides two keywords for declaring a named value: <code>let</code> and var<code>.</code> The choice between them is one of the most important you’ll make, as it signals your intent and has major consequences for safety and performance. The core difference is <strong>mutability</strong>: can the value change after it’s been declared?</p><h3 id=\"let-immutable-constants\"><code>let</code>: Immutable Constants</h3>\n<p>The <code>let</code> keyword declares a <strong>runtime constant</strong>. Once you assign a value to a <code>let</code> binding, it is frozen and <strong>cannot be changed</strong> for the rest of its scope. You should think of it as a named placeholder for a fixed value.</p><pre><code class=\"language-wgsl\">let pi = 3.14159;\nlet base_color = vec3&lt;f32&gt;(1.0, 0.5, 0.2); // An orange color\n\n// The following lines would cause a compilation error:\n// pi = 3.14;                 // ✗ ERROR: Cannot reassign a `let` constant.\n// base_color.r = 0.8;        // ✗ ERROR: Cannot modify a component of a `let` constant.\n</code></pre>\n<h4 id=\"why-you-should-prefer-let\">Why You Should Prefer <code>let</code></h4>\n<p>As a best practice, <strong>you should use <code>let</code> for every value you declare by default</strong>. This habit makes your code safer, more readable, and often more performant.</p><ol>\n<li><strong>Safety and Readability</strong>: When you see let, you have a guarantee that the value will never change within that part of the code. This makes shaders much easier to read and reason about, as you don’t need to track potential modifications. It prevents a whole class of bugs caused by accidental reassignment.</li>\n<li><strong>Performance and Optimization</strong>: Declaring a value as immutable gives the shader compiler critical information. The compiler knows the value is constant, which allows for powerful optimizations. It might perform calculations at compile time (“constant folding”), store the value more efficiently in a register, or remove entire branches of code. In a highly parallel environment like a GPU, working with immutable data is fundamentally more efficient.</li>\n</ol>\n<h3 id=\"var-mutable-variables\"><code>var</code>: Mutable Variables</h3>\n<p>For situations where a value must change after it has been declared, WGSL provides the var keyword. This declares a <strong>mutable variable</strong>, the traditional variable type you might be used to from other languages. Its value can be changed at any time.</p><pre><code class=\"language-wgsl\">// Declare a mutable variable for a counter\nvar counter = 0;\ncounter = counter + 1; // ✓ This is perfectly valid.\n\n// Declare a mutable color to be modified\nvar color = vec3&lt;f32&gt;(1.0, 0.0, 0.0);\ncolor.r = 0.5; // Modify the red component\ncolor.gb = vec2&lt;f32&gt;(0.2, 0.8); // Modify the green and blue components with a swizzle\n</code></pre>\n<h4 id=\"when-to-use-var\">When to Use <code>var</code></h4>\n<p>You should only resort to using <code>var</code> when immutability is not an option. Legitimate scenarios include:</p><ul>\n<li><strong>Accumulators</strong>: When you are summing up values in a loop, such as calculating the total light contribution from multiple light sources.</li>\n</ul>\n<pre><code class=\"language-wgsl\">var total_light = vec3&lt;f32&gt;(0.0);\nfor (var i = 0; i &lt; 4; i = i + 1) {\n    total_light = total_light + calculate_light_contribution(i);\n}\n</code></pre>\n<ul>\n<li><strong>Loop Counters</strong>: The counter in a for loop must be a <code>var</code>.</li>\n<li><strong>Step-by-Step Modification</strong>: When you start with a base value and apply a series of complex, conditional modifications to it.</li>\n</ul>\n<pre><code class=\"language-wgsl\">var final_color = texture_color;\nif (is_in_shadow) {\n    final_color = final_color * 0.5;\n}\nfinal_color = apply_fog(final_color, distance);\n</code></pre>\n<p>Even in this case, it’s often possible (and clearer) to rewrite the logic using <code>let</code> for each stage, as it forces a more explicit data flow.</p><h3 id=\"type-inference\">Type Inference</h3>\n<p>WGSL’s compiler is smart and can often infer a variable’s type from the value you assign to it.</p><pre><code class=\"language-wgsl\">let x = 1.0;                    // Inferred as f32\nlet pos = vec3(1.0, 2.0, 3.0);  // Components are f32, so inferred as vec3&lt;f32&gt;\nlet count = 0;                  // Inferred as i32\nlet flag = true;                // Inferred as bool\n</code></pre>\n<p>Technically, number literals like <code>1</code> or <code>1.0</code> start as “abstract” integers or floats. The compiler gives them a concrete type (<code>i32</code>, <code>f32</code>, etc.) the first time they are used in a context that requires one. For <code>let count = 0;</code>, the default concrete type for an abstract integer is <code>i32</code>. This is why type inference works so smoothly.</p><p>While inference is convenient, being explicit about types can sometimes make your code clearer and prevent subtle bugs, especially when you intend to use a less common type like <code>u32</code>.</p><pre><code class=\"language-wgsl\">// Explicit types for clarity\nlet x: f32 = 1.0;\nlet pos: vec3&lt;f32&gt; = vec3(1.0, 2.0, 3.0);\nlet frame_index: u32 = 0u; // Explicitly an unsigned integer\n</code></pre>\n<h2 id=\"putting-it-all-together-a-common-workflow\">Putting It All Together: A Common Workflow</h2>\n<p>We’ve learned about scalars, vectors, and the let keyword as separate concepts. Now, let’s put them all together. The following snippet demonstrates a common and powerful workflow you’ll use constantly in your shaders: starting with base values and creating new ones in a series of clear, immutable steps.</p><p>This isn’t a runnable demo, but rather a perfect illustration of how the pieces fit together to achieve a result.</p><pre><code class=\"language-wgsl\">@fragment\nfn fragment(in: VertexOutput) -&gt; @location(0) vec4&lt;f32&gt; {\n    // Step 1: Define our starting point with `let` and a vector constructor.\n    // This base value itself won&#39;t change; we will create new constants based on it.\n    let base_color = vec3&lt;f32&gt;(1.0, 0.5, 0.2);\n\n    // Step 2: Adjust brightness with scalar-vector multiplication.\n    // In a real shader, this could be a shadow calculation. We&#39;re just making\n    // the base color 50% darker via component-wise multiplication.\n    let darker_orange = base_color * 0.5;\n\n    // Step 3: Blend with another color using vector arithmetic.\n    // We create a final color that is 70% our `darker_orange` and 30% a\n    // cool blue accent color. This is a manual linear interpolation.\n    let accent_color = vec3&lt;f32&gt;(0.2, 0.3, 0.8);\n    let blended_color = darker_orange * 0.7 + accent_color * 0.3;\n\n    // Step 4: Construct the final `vec4` output.\n    // The fragment shader must return an RGBA color. We construct this\n    // by combining our final `vec3` result with a scalar `f32` for the alpha.\n    let final_output = vec4&lt;f32&gt;(blended_color, 1.0);\n\n    return final_output;\n}\n</code></pre>\n<h3 id=\"deconstructing-the-process\">Deconstructing the Process</h3>\n<p>This short example is a microcosm of everyday shader programming, demonstrating several key concepts in a practical flow:</p><ol>\n<li><strong>Immutability by Default</strong>: We use <code>let</code> to define each stage of the color. This makes the code easy to follow - <code>base_color</code> is always the original orange, <code>darker_orange</code> is always the half-bright version, and so on. There are no surprise mutations, which makes the logic simple to debug.</li>\n<li><strong>Vector as a Unit</strong>: We treat <code>base_color</code> and <code>accent_color</code> as single entities, even though they contain three separate <code>f32</code> values. All our math (<code>*</code> and <code>+</code>) operates on them as a whole, which is clean and intuitive.</li>\n<li><strong>Component-Wise Math in Action</strong>: The multiplication <code>darker_orange * 0.7</code> isn’t a dot product; it’s a scaling of each color channel (R, G, and B) independently. This component-wise behavior is exactly what we need for tinting and blending colors.</li>\n<li><strong>Vector Construction Flexibility</strong>: We see two kinds of construction: <code>vec3&lt;f32&gt;(r, g, b)</code> to define the initial colors from scalars, and the powerful <code>vec4&lt;f32&gt;(vec3, a)</code> to compose the final output by combining an existing <code>vec3</code> with a new scalar alpha channel.</li>\n</ol>\n<p>By following this pattern - starting with base values, applying a series of transformations and blends to create new <code>let</code> constants, and finally constructing the required output - you can build complex visual effects in a clean, readable, and performant way.</p><hr>\n<h2 id=\"complete-example-vector-operations-visualizer\">Complete Example: Vector Operations Visualizer</h2>\n<p>Theory is essential, but seeing is believing. To make these abstract concepts concrete, we’ll build a simple, interactive shader in Bevy. This shader won’t create a realistic object; instead, it will act as a diagnostic tool, allowing us to “see” vector operations in real-time.</p><h3 id=\"our-goal\">Our Goal</h3>\n<p>We will create a custom material for a sphere that can cycle through five different visualization modes by pressing a key. Each mode will apply a different vector operation to the sphere’s base color, visually demonstrating concepts like component access, swizzling, and arithmetic.</p><h3 id=\"what-this-project-demonstrates\">What This Project Demonstrates</h3>\n<ul>\n<li><strong>Component Access</strong>: How to isolate and use a single component of a vector (e.g., <code>.r</code>).</li>\n<li><strong>Swizzling</strong>: The power of rearranging vector components on the fly (e.g., <code>.bgr</code>).</li>\n<li><strong>Vector Arithmetic</strong>: The visual result of component-wise addition and multiplication.</li>\n<li><strong>Vector Construction</strong>: How to build new vectors by combining smaller vectors and scalars.</li>\n<li><strong>Bevy Integration</strong>: The basic structure of a custom <code>Material</code> in Bevy 0.16 and how to pass data (our <code>demo_mode</code>) from Rust to a WGSL shader.</li>\n</ul>\n<h3 id=\"the-shader-assetsshadersvector_demowgsl\">The Shader (<code>assets/shaders/vector_demo.wgsl</code>)</h3>\n<p>This single WGSL file contains both our vertex and fragment shaders. The vertex shader is standard; it calculates the world position and normal for each vertex and passes them to the next stage.</p><p>The fragment shader is where the magic happens. It first calculates a <code>base</code> color from the interpolated world normal. Then, using an <code>if</code> chain, it checks the <code>material.demo_mode</code> uniform (sent from our Rust code) to decide which vector operation to perform, altering the final color of the pixel accordingly.</p><pre><code class=\"language-wgsl\">#import bevy_pbr::mesh_functions\n#import bevy_pbr::view_transformations::position_world_to_clip\n#import bevy_pbr::forward_io::VertexOutput\n\nstruct VectorDemoMaterial {\n    demo_mode: u32,\n}\n\n@group(2) @binding(0)\nvar&lt;uniform&gt; material: VectorDemoMaterial;\n\n@vertex\nfn vertex(\n    @builtin(instance_index) instance_index: u32,\n    @location(0) position: vec3&lt;f32&gt;,\n    @location(1) normal: vec3&lt;f32&gt;,\n) -&gt; VertexOutput {\n    var out: VertexOutput;\n\n    let world_from_local = mesh_functions::get_world_from_local(instance_index);\n    let world_position = mesh_functions::mesh_position_local_to_world(\n        world_from_local,\n        vec4&lt;f32&gt;(position, 1.0)\n    );\n\n    out.position = position_world_to_clip(world_position.xyz);\n    out.world_normal = mesh_functions::mesh_normal_local_to_world(normal, instance_index);\n    out.world_position = world_position;\n\n    return out;\n}\n\n@fragment\nfn fragment(in: VertexOutput) -&gt; @location(0) vec4&lt;f32&gt; {\n    // Create a base color from the normal\n    let base = (in.world_normal + 1.0) * 0.5;\n\n    // Mode 0: RGB channels separately\n    if material.demo_mode == 0u {\n        // Show only red channel\n        return vec4&lt;f32&gt;(base.r, 0.0, 0.0, 1.0);\n    }\n\n    // Mode 1: Swizzling demonstration\n    if material.demo_mode == 1u {\n        // Reverse the RGB channels (BGR)\n        let swizzled = base.bgr;\n        return vec4&lt;f32&gt;(swizzled, 1.0);\n    }\n\n    // Mode 2: Vector arithmetic\n    if material.demo_mode == 2u {\n        // Add a constant color\n        let added = base + vec3&lt;f32&gt;(0.0, 0.3, 0.0);  // Add green\n        return vec4&lt;f32&gt;(added, 1.0);\n    }\n\n    // Mode 3: Vector multiplication\n    if material.demo_mode == 3u {\n        // Multiply by a color (component-wise)\n        let tinted = base * vec3&lt;f32&gt;(1.0, 0.5, 0.5);  // Reduce green and blue\n        return vec4&lt;f32&gt;(tinted, 1.0);\n    }\n\n    // Mode 4: Component extraction and reconstruction\n    if material.demo_mode == 4u {\n        // Extract xy, ignore z, add new z\n        let xy = base.xy;\n        let reconstructed = vec3&lt;f32&gt;(xy, 0.5);  // Force z to 0.5\n        return vec4&lt;f32&gt;(reconstructed, 1.0);\n    }\n\n    // Default: Original\n    return vec4&lt;f32&gt;(base, 1.0);\n}\n</code></pre>\n<h3 id=\"the-rust-material-srcmaterialsvector_demors\">The Rust Material (<code>src/materials/vector_demo.rs</code>)</h3>\n<p>This is the Rust-side definition of our material. It’s a simple struct that mirrors the <code>VectorDemoMaterial</code> struct in our shader, allowing Bevy’s rendering engine to send our chosen <code>demo_mode</code> value to the GPU.</p><pre><code class=\"language-rust\">use bevy::prelude::*;\nuse bevy::render::render_resource::{AsBindGroup, ShaderRef};\n\n#[derive(Asset, TypePath, AsBindGroup, Debug, Clone)]\npub struct VectorDemoMaterial {\n    #[uniform(0)]\n    pub demo_mode: u32,\n}\n\nimpl Material for VectorDemoMaterial {\n    fn fragment_shader() -&gt; ShaderRef {\n        &quot;shaders/vector_demo.wgsl&quot;.into()\n    }\n\n    fn vertex_shader() -&gt; ShaderRef {\n        &quot;shaders/vector_demo.wgsl&quot;.into()\n    }\n}\n</code></pre>\n<p>Don’t forget to add it to <code>src/materials/mod.rs</code>:</p><pre><code class=\"language-rust\">// ... other materials\npub mod vector_demo;\n</code></pre>\n<h3 id=\"the-demo-module-srcdemosvector_demors\">The Demo Module (<code>src/demos/vector_demo.rs</code>)</h3>\n<p>This Rust module sets up our Bevy scene. It spawns a sphere with our custom material, adds a camera and light, and sets up the UI text. Most importantly, it contains the <code>cycle_demo_mode</code> system, which listens for the spacebar press and updates the <code>demo_mode</code> field on our material, triggering the change in the shader.</p><pre><code class=\"language-rust\">use crate::materials::vector_demo::VectorDemoMaterial;\nuse bevy::prelude::*;\n\npub fn run() {\n    App::new()\n        .add_plugins(DefaultPlugins)\n        .add_plugins(MaterialPlugin::&lt;VectorDemoMaterial&gt;::default())\n        .add_systems(Startup, setup)\n        .add_systems(Update, (rotate_camera, cycle_demo_mode))\n        .run();\n}\n\nfn setup(\n    mut commands: Commands,\n    mut meshes: ResMut&lt;Assets&lt;Mesh&gt;&gt;,\n    mut materials: ResMut&lt;Assets&lt;VectorDemoMaterial&gt;&gt;,\n) {\n    // Spawn a sphere\n    commands.spawn((\n        Mesh3d(meshes.add(Sphere::new(1.0).mesh().uv(32, 18))),\n        MeshMaterial3d(materials.add(VectorDemoMaterial { demo_mode: 0 })),\n    ));\n\n    // Light\n    commands.spawn((\n        PointLight {\n            shadows_enabled: true,\n            ..default()\n        },\n        Transform::from_xyz(4.0, 8.0, 4.0),\n    ));\n\n    // Camera\n    commands.spawn((\n        Camera3d::default(),\n        Transform::from_xyz(-2.5, 4.5, 9.0).looking_at(Vec3::ZERO, Vec3::Y),\n    ));\n\n    // UI\n    commands.spawn((\n        Text::new(&quot;Press SPACE to cycle modes\\nMode 0: Red channel only&quot;),\n        Node {\n            position_type: PositionType::Absolute,\n            top: Val::Px(10.0),\n            left: Val::Px(10.0),\n            ..default()\n        },\n    ));\n}\n\nfn rotate_camera(time: Res&lt;Time&gt;, mut camera_query: Query&lt;&amp;mut Transform, With&lt;Camera3d&gt;&gt;) {\n    for mut transform in camera_query.iter_mut() {\n        let radius = 9.0;\n        let angle = time.elapsed_secs() * 0.5;\n        transform.translation.x = angle.cos() * radius;\n        transform.translation.z = angle.sin() * radius;\n        transform.look_at(Vec3::ZERO, Vec3::Y);\n    }\n}\n\nfn cycle_demo_mode(\n    keyboard: Res&lt;ButtonInput&lt;KeyCode&gt;&gt;,\n    mut materials: ResMut&lt;Assets&lt;VectorDemoMaterial&gt;&gt;,\n    mut text_query: Query&lt;&amp;mut Text&gt;,\n) {\n    if keyboard.just_pressed(KeyCode::Space) {\n        for (_, material) in materials.iter_mut() {\n            material.demo_mode = (material.demo_mode + 1) % 5;\n\n            for mut text in text_query.iter_mut() {\n                **text = match material.demo_mode {\n                    0 =&gt; &quot;Press SPACE to cycle modes\\nMode 0: Red channel only&quot;.to_string(),\n                    1 =&gt; &quot;Press SPACE to cycle modes\\nMode 1: BGR swizzle (reversed)&quot;.to_string(),\n                    2 =&gt; &quot;Press SPACE to cycle modes\\nMode 2: Add green (vector addition)&quot;\n                        .to_string(),\n                    3 =&gt; &quot;Press SPACE to cycle modes\\nMode 3: Color tint (vector multiplication)&quot;\n                        .to_string(),\n                    4 =&gt; &quot;Press SPACE to cycle modes\\nMode 4: XY extraction with new Z&quot;.to_string(),\n                    _ =&gt; &quot;Unknown mode&quot;.to_string(),\n                };\n            }\n        }\n    }\n}\n</code></pre>\n<p>Don’t forget to add it to <code>src/demos/mod.rs</code>:</p><pre><code class=\"language-rust\">// ... other demoss\npub mod vector_demo;\n</code></pre>\n<p>And register it in <code>src/main.rs</code>:</p><pre><code class=\"language-rust\">Demo {\n    number: &quot;1.2&quot;,\n    title: &quot;WGSL Fundamentals - Data Types &amp; Variables&quot;,\n    run: demos::vector_demo::run,\n},\n</code></pre>\n<h3 id=\"running-the-demo\">Running the Demo</h3>\n<p>When you run the project, you will see a multi-colored sphere. Pressing the spacebar will cycle through the five different debug visualizations, each revealing how a different vector operation affects the final color.</p><h4 id=\"controls\">Controls</h4>\n<table>\n<thead>\n<tr>\n<th>Control</th>\n<th>Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>SPACE</strong></td>\n<td>Cycle to the next visualization mode (0 -&gt; 1 -&gt; 2 -&gt; 3 -&gt; 4 -&gt; 0).</td>\n</tr>\n</tbody></table>\n<h4 id=\"what-youre-seeing\">What You’re Seeing</h4>\n<figure class=\"post__image\"><img src=\"/media/files/1.2%20-%20screenshot%20-%201.png\" alt=\"screenshot 1\" data-is-external-image=\"true\"></figure>\n<figure class=\"post__image\"><img src=\"/media/files/1.2%20-%20screenshot%20-%202.png\" alt=\"screenshot 2\" data-is-external-image=\"true\"></figure>\n<figure class=\"post__image\"><img src=\"/media/files/1.2%20-%20screenshot%20-%203.png\" alt=\"screenshot 3\" data-is-external-image=\"true\"></figure>\n<figure class=\"post__image\"><img src=\"/media/files/1.2%20-%20screenshot%20-%204.png\" alt=\"screenshot 4\" data-is-external-image=\"true\"></figure>\n<figure class=\"post__image\"><img src=\"/media/files/1.2%20-%20screenshot%20-%205.png\" alt=\"screenshot 5\" data-is-external-image=\"true\"></figure><p>Each mode corresponds to a different branch in our fragment shader’s logic.</p><table>\n<thead>\n<tr>\n<th>Mode</th>\n<th>Description</th>\n<th>What It Proves</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>0 - Red Channel Only</strong></td>\n<td>The sphere is colored only with the red component of the base color.</td>\n<td>Demonstrates <strong>component access</strong> (<code>base.r</code>). We’ve isolated a single <code>f32</code> from a <code>vec3</code>.</td>\n</tr>\n<tr>\n<td><strong>1 - BGR Swizzle</strong></td>\n<td>The colors are reversed. Areas that were red are now blue, and vice-versa.</td>\n<td>Demonstrates <strong>swizzling</strong> (<code>base.bgr</code>). We created a new <code>vec3</code> by reordering the components of the original.</td>\n</tr>\n<tr>\n<td><strong>2 - Vector Addition</strong></td>\n<td>The entire sphere appears brighter and greener.</td>\n<td>Demonstrates <strong>component-wise addition</strong>. We added <code>(0.0, 0.3, 0.0)</code> to every single pixel’s color, increasing its green channel.</td>\n</tr>\n<tr>\n<td><strong>3 - Color Tint</strong></td>\n<td>The sphere appears more reddish-orange, with the greens and blues muted.</td>\n<td>Demonstrates <strong>component-wise multiplication</strong>. We scaled the G and B channels by <code>0.5</code>, effectively tinting the entire result.</td>\n</tr>\n<tr>\n<td><strong>4 - XY Reconstruction</strong></td>\n<td>The color is now only composed of red and green, with a constant blue value of 0.5 across the whole sphere.</td>\n<td>Demonstrates <strong>construction and extraction</strong>. We extracted a <code>vec2 (base.xy)</code> and used it to construct a new <code>vec3</code>.</td>\n</tr>\n</tbody></table>\n<h2 id=\"key-takeaways\">Key Takeaways</h2>\n<p>This article introduced you to the alphabet of the WGSL language. Before moving on, ensure you have a solid grasp of these core concepts, as they are the foundation upon which all shader logic is built.</p><ol>\n<li><strong>Scalars are the Atomic Units, with <code>f32</code> Being King</strong>.\n WGSL provides the basic building blocks of <code>f32</code> (floats), <code>i32</code>/<code>u32</code> (integers), and bool (booleans). Remember that nearly all graphics math is done with <code>f32</code>, and you must be explicit with literals (use <code>1.0</code> for a float, <code>1u</code> for an unsigned integer).</li>\n<li><strong>Vectors are the Workhorse for All Graphics Data.</strong><br> Positions, colors, directions, texture coordinates - everything is represented by vectors (<code>vec2</code>, <code>vec3</code>, <code>vec4</code>). Learning to think in terms of vectors is the most important step in becoming a shader programmer. They are not just data containers; they are the native language of the GPU.</li>\n<li><strong>Vector Operations are Fast, Powerful, and Component-Wise.</strong><br> The GPU is optimized to perform math on vectors. Operations like addition, subtraction, and multiplication are applied to each component independently. This is perfect for tasks like blending colors or offsetting positions. <strong>Swizzling</strong> (<code>.rgba</code>, <code>.xy</code>, <code>.bgr</code>) is a zero-cost hardware feature that lets you efficiently rearrange and create new vectors from existing ones.</li>\n<li><strong>Matrices are the Machines of Transformation.</strong><br> While we’ll cover the deep math later, understand now that matrices (especially <code>mat4x4&lt;f32&gt;</code>) are the tools used to move, rotate, scale, and project your vectors from one coordinate space to another. The core of a vertex shader is applying matrix transformations to vertex positions.</li>\n<li><strong>Prefer Immutable let for Safety and Performance.</strong><br> Use let to declare constants by default. This makes your code safer, easier to reason about, and provides crucial information to the shader compiler, enabling powerful optimizations. Only use var for mutable variables when you have a specific need to change a value after its initial declaration, such as an accumulator in a loop.</li>\n</ol>\n<h2 id=\"whats-next\">What’s Next?</h2>\n<p>You have now learned the “nouns” of the WGSL language - the fundamental data types and variables used to represent all the data in your shader, from a single boolean flag to a complex transformation matrix. You know how to create, store, and perform basic math on this data.</p><p>But data on its own is static. To bring our shaders to life, we need to create logic. In the next article, we will learn the “verbs” and “grammar” of WGSL. We will explore how to organize your code into reusable <strong>functions</strong> and how to make decisions and repeat operations using <strong>control flow</strong> structures like <code>if/else</code> and <code>for</code> loops.</p><p><em>Next up:</em> <a href=\"https://hexbee.hashnode.dev/13-wgsl-fundamentals-functions-and-control-flow\"><strong><em>1.3 - WGSL Fundamentals - Functions &amp; Control Flow</em></strong></a></p><hr>\n<h2 id=\"quick-reference\">Quick Reference</h2>\n<p>A cheat sheet for the fundamental building blocks of the WGSL language.</p><h3 id=\"scalar-types\">Scalar Types</h3>\n<table>\n<thead>\n<tr>\n<th>Type</th>\n<th>Description</th>\n<th>Example Literal</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>f32</code></td>\n<td>32-bit floating-point number. The default for most math.</td>\n<td><code>1.0</code>, <code>-0.5</code>, <code>3.14</code></td>\n</tr>\n<tr>\n<td><code>i32</code></td>\n<td>32-bit signed integer. The default for integers.</td>\n<td><code>42</code>, <code>-10</code>, <code>0</code></td>\n</tr>\n<tr>\n<td><code>u32</code></td>\n<td>32-bit unsigned integer (non-negative).</td>\n<td><code>0u</code>, <code>255u</code>, <code>100u</code></td>\n</tr>\n<tr>\n<td><code>bool</code></td>\n<td>A boolean value.</td>\n<td><code>true</code>, <code>false</code></td>\n</tr>\n</tbody></table>\n<h3 id=\"variable-declaration\">Variable Declaration</h3>\n<ul>\n<li><code>let name = value;</code>: Declares an <strong>immutable constant</strong>. Its value cannot be changed. <strong>Use this by default.</strong></li>\n<li><code>var name = value;</code>: Declares a <strong>mutable variable</strong>. Its value can be reassigned. Use only when necessary (e.g., accumulators, loop counters).</li>\n</ul>\n<h3 id=\"vector-types\">Vector Types</h3>\n<p>The workhorse of shader programming. <code>T</code> can be <code>f32</code>, <code>i32</code>, <code>u32</code>, or bool.</p><p><strong>Syntax:</strong> <code>vecN&lt;T&gt;</code> (e.g., <code>vec3&lt;f32&gt;</code>)</p><h4 id=\"construction\">Construction</h4>\n<pre><code class=\"language-wgsl\">// From components\nlet v3 = vec3&lt;f32&gt;(1.0, 2.0, 3.0);\n\n// From a single value (&quot;splat&quot;)\nlet v3 = vec3&lt;f32&gt;(0.5); // -&gt; vec3(0.5, 0.5, 0.5)\n\n// Combining smaller types\nlet xy = vec2&lt;f32&gt;(1.0, 2.0);\nlet v3 = vec3&lt;f32&gt;(xy, 3.0); // -&gt; vec3(1.0, 2.0, 3.0)\nlet v4 = vec4&lt;f32&gt;(v3, 1.0); // -&gt; vec4(1.0, 2.0, 3.0, 1.0)\n</code></pre>\n<h4 id=\"access--swizzling\">Access &amp; Swizzling</h4>\n<pre><code class=\"language-wgsl\">let v = vec4&lt;f32&gt;(1.0, 2.0, 3.0, 4.0);\n\n// Access (all are equivalent for the first component)\nlet c0_a = v.x; // -&gt; 1.0\nlet c0_b = v.r; // -&gt; 1.0\nlet c0_c = v[0]; // -&gt; 1.0\n\n// Swizzling (creating new vectors)\nlet v2 = v.xy;      // -&gt; vec2(1.0, 2.0)\nlet v3 = v.bgr;     // -&gt; vec3(3.0, 2.0, 1.0) (reordered)\nlet v3 = v.rrr;     // -&gt; vec3(1.0, 1.0, 1.0) (duplicated)\nlet v2 = v.wz;      // -&gt; vec2(4.0, 3.0)\n</code></pre>\n<h4 id=\"arithmetic-component-wise\">Arithmetic (Component-Wise)</h4>\n<pre><code class=\"language-wgsl\">let a = vec2&lt;f32&gt;(1.0, 2.0);\nlet b = vec2&lt;f32&gt;(3.0, 4.0);\n\nlet sum = a + b;    // -&gt; vec2(4.0, 6.0)\nlet prod = a * b;   // -&gt; vec2(3.0, 8.0)\nlet scaled = a * 2.0; // -&gt; vec2(2.0, 4.0)\n</code></pre>\n<h3 id=\"matrix-types\">Matrix Types</h3>\n<p>Used for transformations. <code>C</code>=Columns, <code>R</code>=Rows.</p><p><strong>Syntax:</strong> <code>matCxR&lt;T&gt;</code> (e.g., <code>mat4x4&lt;f32&gt;</code>)</p><ul>\n<li><strong>Column-Major</strong>: Data is organized by columns.</li>\n<li><strong>Access</strong>: <code>matrix[column_index][row_index]</code></li>\n<li><strong>Multiplication</strong>: <code>transformed_vector = matrix * vector</code> (This is a mathematical transformation, not component-wise).</li>\n</ul>\n",
            "image": "https://xav.github.io/media/posts/5/cover2.png",
            "author": {
                "name": "Xavier Basty Kjellberg"
            },
            "tags": [
                   "wgsl",
                   "shaders",
                   "rust",
                   "bevy"
            ],
            "date_published": "2025-09-06T19:31:00+02:00",
            "date_modified": "2025-12-13T19:52:15+01:00"
        },
        {
            "id": "https://xav.github.io/11-understanding-the-graphics-pipeline/",
            "url": "https://xav.github.io/11-understanding-the-graphics-pipeline/",
            "title": "1.1 - Understanding the Graphics Pipeline",
            "summary": "What We’re Learning Welcome to the start of your shader programming journey! Before we can write a single line of WGSL code to create shimmering&hellip;",
            "content_html": "<h2 id=\"what-were-learning\">What We’re Learning</h2>\n<p>Welcome to the start of your shader programming journey! Before we can write a single line of WGSL code to create shimmering water or a glowing sword, we must first answer a fundamental question: <strong>what exactly is a shader?</strong></p><p>At its core, a shader is a small, highly-focused program that you, the developer, write. Unlike the Rust code that runs on your computer’s main processor (the CPU), a shader runs directly on the thousands of parallel cores of your Graphics Processing Unit (GPU). This gives you direct, low-level control over how your game’s graphics are rendered. Shaders are the modern key to controlling the look, feel, and performance of everything you see in a real-time 3D application.</p><p>This first chapter pulls back the curtain on the rendering process. We will build a complete mental model of the <strong>graphics pipeline</strong> - the step-by-step assembly line a GPU uses to turn the raw data of your 3D models into the final, vibrant pixels on your screen.</p><p>Understanding this pipeline is the single most important foundation for shader programming. Without it, writing shader code is like trying to assemble a car without knowing what an engine or a wheel does. With it, every new concept will have a clear place to belong.</p><p>By the end of this chapter, you’ll understand:</p><ul>\n<li><strong>The Big Picture:</strong> The journey of your 3D model data from the CPU (your Bevy app) to the GPU (the rendering factory).</li>\n<li><strong>The “Why” of GPUs:</strong> Why we need a specialized processor for graphics and how its parallel design is perfect for rendering.</li>\n<li><strong>The Vertex’s Journey:</strong> How a single point in your 3D model travels through a series of “coordinate spaces” - from its local origin to its final position on your screen.</li>\n<li><strong>The Two Programmable Stages:</strong> The specific jobs of the <strong>Vertex Shader</strong> (controlling shape and position) and the <strong>Fragment Shader</strong> (controlling color and appearance), and how your WGSL code fits into this process.</li>\n</ul>\n<h2 id=\"the-big-picture-cpu-to-screen\">The Big Picture: CPU to Screen</h2>\n<p>Let’s start with the fundamental question: <strong>How does a 3D model in your Bevy game become the final, colored pixels on your screen?</strong></p><p>The process is a hand-off of instructions and data from a general-purpose processor (the CPU) to a highly specialized one (the GPU). The CPU decides <em>what</em> needs to be drawn, while the GPU figures out how to draw it at incredible speed. The GPU performs this task using a dedicated assembly line called the <strong>graphics pipeline</strong>.</p><p>Here is a simplified map of that journey:</p><pre><code class=\"language-plaintext\">┌───────────────────────────────────────────┐\n│              CPU: The Director            │\n│          (Your Bevy / Rust Code)          │\n│                                           │\n│  - Runs game logic, physics, AI, etc.     │\n│  - Decides WHAT to draw this frame.       │\n│  - Packages all necessary data for GPU.   │\n└───────────────────────────────────────────┘\n                       │\n                       │ Sends a &quot;Draw Command&quot; with all required data\n                       ↓\n  ═════════════════════ GPU BOUNDARY ═════════════════════\n                       ↓\n┌───────────────────────────────────────────┐\n│             GPU: The Factory              │\n│       (Massively Parallel Hardware)       │\n└───────────────────────────────────────────┘\n                       │\n                       ▼\n┌───────────────────────────────────────────┐\n│            1. VERTEX SHADER               │ «── [ YOUR WGSL CODE RUNS HERE ]\n├───────────────────────────────────────────┤\n│ INPUT:  A single vertex from a mesh       │\n│         (e.g., its local position, UVs).  │\n│                                           │\n│ JOB:    Calculate the vertex&#39;s final      │\n│         position on the screen.           │\n│                                           │\n│ OUTPUT: The vertex&#39;s position in          │\n│         &quot;Clip Space&quot; &amp; other data         │\n│         (like normals) for the next stage.│\n└───────────────────────────────────────────┘\n                       │\n                       │ (GPU groups 3 processed vertices into a triangle)\n                       ↓\n┌───────────────────────────────────────────┐\n│            2. RASTERIZATION               │ «── [ AUTOMATIC HARDWARE STAGE ]\n├───────────────────────────────────────────┤\n│ INPUT:  A triangle in screen space.       │\n│                                           │\n│ JOB:    Determine which pixels the        │\n│         triangle covers.                  │\n│                                           │\n│ OUTPUT: A stream of &quot;Fragments.&quot;          │\n│         (A fragment is a potential pixel  │\n│         with smoothly interpolated data). │\n└───────────────────────────────────────────┘\n                       │\n                       ↓\n┌───────────────────────────────────────────┐\n│           3. FRAGMENT SHADER              │ «── [ YOUR WGSL CODE RUNS HERE ]\n├───────────────────────────────────────────┤\n│ INPUT:  A single fragment with its        │\n│         interpolated data (e.g., UVs).    │\n│                                           │\n│ JOB:    Calculate the final color for     │\n│         that specific fragment.           │\n│                                           │\n│ OUTPUT: A single RGBA color.              │\n└───────────────────────────────────────────┘\n                       │\n                       ↓\n┌───────────────────────────────────────────┐\n│           4. OUTPUT MERGER                │ «── [ AUTOMATIC HARDWARE STAGE ]\n├───────────────────────────────────────────┤\n│ JOB:    Take the colored fragment and     │\n│         merge it into the final image.    │\n│                                           │\n│       - Performs Depth Test (is this      │\n│         fragment behind something else?). │\n│       - Performs Blending (for            │\n│         transparency effects).            │\n│       - Writes the final color.           │\n└───────────────────────────────────────────┘\n                       │\n                       ▼\n            ▓▓▓ PIXELS ON SCREEN ▓▓▓\n</code></pre>\n<p>This process spans two distinct worlds, each with a specific job.</p><h3 id=\"the-cpu-side-bevyrust-the-director\">The CPU Side (Bevy/Rust): The Director</h3>\n<p>Think of your CPU and your Bevy code as the <strong>director of a film</strong>. It’s smart, flexible, and responsible for all the high-level decision-making. For every single frame (60 times a second!), it runs your game logic, updates physics, handles input, and determines what needs to be on screen and where it should be.</p><p>Its final job for rendering is to prepare a detailed set of instructions and data for the GPU. This “frame package” includes:</p><ul>\n<li><strong>Mesh Data</strong>: The raw vertex information (positions, normals, UV coordinates) for each model.</li>\n<li><strong>Material Data</strong>: Your shader’s settings, like colors, roughness values, and which textures to use.</li>\n<li><strong>Transformation Data</strong>: The matrices that define each object’s position, rotation, and scale in the world.</li>\n<li><strong>Global Data</strong>: Information about the entire scene, like the camera’s position (View Matrix), its lens settings (Projection Matrix), and the location of lights.</li>\n</ul>\n<p>Once this package is assembled, the CPU sends it across the bus to the GPU and effectively says, “Here, render this.” The CPU’s main rendering job for this frame is now complete.</p><h3 id=\"the-gpu-side-shaders-the-vfx-studio\">The GPU Side (Shaders): The VFX Studio</h3>\n<p>Think of the GPU as a state-of-the-art <strong>VFX studio</strong> with an army of digital artists, each with a very specific job. This studio is built for one purpose: turning the director’s brief into a final, beautifully rendered image with incredible speed. Their process is the graphics pipeline.</p><p>When the brief arrives at the studio:</p><ol>\n<li><strong>The Geometry &amp; Layout Artists (Vertex Shader):</strong> The first team gets the brief. This team consists of thousands of artists. Each artist is assigned a single corner (a <strong>vertex</strong>) of an actor or prop. Their only job is to calculate exactly where that specific corner will appear in the final camera shot, based on the actor’s position and the camera’s lens. They don’t color anything; they just map out the structure of the scene from the camera’s perspective.</li>\n<li><strong>The Rendering Artists (Fragment Shader):</strong> After the layout is done, a second, even larger army of artists takes over. There are millions of them - one for every pixel of the final image. Each artist is assigned a single pixel to paint (a <strong>fragment</strong>). They look at the director’s notes for that surface (the material, the textures) and the lighting setup. Then, they calculate and apply the final, precise color for their one tiny pixel.</li>\n</ol>\n<p>This analogy directly maps to the GPU’s strengths:</p><ul>\n<li><strong>Specialization:</strong> The geometry artists only do positioning; the rendering artists only do coloring.</li>\n<li><strong>Parallelism:</strong> Millions of rendering artists can paint their individual pixels all at the exact same time, without needing to talk to each other. This is what makes the GPU so fast.</li>\n</ul>\n<p>Your WGSL shader code is the set of instructions - the “artistic direction” - you give to these two teams of digital artists.</p><h2 id=\"why-the-gpu-understanding-parallelism\">Why the GPU? Understanding Parallelism</h2>\n<p>It’s a fair question: your computer’s Central Processing Unit (CPU) is an incredibly powerful and fast processor. Why can’t it just draw the triangles? Why do we need a separate, specialized piece of hardware like a Graphics Processing Unit (GPU)?</p><p>The answer lies not in raw clock speed, but in a fundamentally different architectural philosophy: <strong>Serial vs. Parallel processing</strong>.</p><h3 id=\"the-cpu-a-master-chef\">The CPU: A Master Chef</h3>\n<p>Think of your CPU as a <strong>master chef in a world-class kitchen</strong>.</p><ul>\n<li><strong>It is brilliant and versatile.</strong> It can follow any recipe (run any program), handle complex sequential steps, improvise when needed (handle interrupts and varied tasks), and manage the entire kitchen (the operating system).</li>\n<li><strong>It has a few, very powerful cores.</strong> Like having 8 or 16 highly trained sous-chefs, it can work on a handful of complex, different dishes at once.</li>\n</ul>\n<p>If you asked this master chef to prepare a single, elaborate seven-course meal, they would excel. But if you asked them to make ten million identical hamburgers, the entire restaurant would grind to a halt. The chef’s genius is wasted on such a simple, repetitive task; its strength is in complexity and flexibility, not mass production.</p><h3 id=\"the-gpu-a-hyper-efficient-assembly-line\">The GPU: A Hyper-Efficient Assembly Line</h3>\n<p>Now, think of your GPU as a <strong>massive hamburger assembly line that stretches for miles</strong>.</p><ul>\n<li><strong>It is highly specialized.</strong> It’s not designed to create new recipes. It’s designed to execute one simple recipe over and over again with breathtaking speed.</li>\n<li><strong>It has thousands of simple cores.</strong> Instead of a few master chefs, you have thousands of line cooks. Each cook is trained for just one or two simple tasks - place the patty, add the cheese - but they all work at the exact same time.</li>\n</ul>\n<p>This factory can’t prepare a seven-course meal, but it can produce those ten million identical hamburgers in the blink of an eye. This is what we call <strong>“pleasingly parallel”</strong> work.</p><h3 id=\"graphics-is-a-pleasingly-parallel-problem\">Graphics is a “Pleasingly Parallel” Problem</h3>\n<p>Rendering a 3D scene is the ultimate assembly-line task. The core operations are simple, repetitive, and most importantly, <strong>independent</strong>.</p><ul>\n<li>The calculation for vertex A’s final position does not depend on vertex B’s position.</li>\n<li>The calculation for pixel #1’s color does not depend on pixel #2’s color.</li>\n</ul>\n<p>They can all be processed simultaneously.</p><p>Let’s put this into perspective. When rendering a moderately complex scene with 100,000 triangles on a standard 1080p display, for a single frame, you are asking the hardware to perform approximately:</p><ul>\n<li><strong>300,000 vertex shader executions</strong> (one for each vertex)</li>\n<li><strong>Millions of fragment shader executions</strong> (one for each pixel covered by a triangle)</li>\n</ul>\n<p>And this has to happen <strong>60 times every second</strong> for smooth gameplay.</p><p>This is the “ten million hamburgers” problem. A CPU, with its few brilliant cores, would be overwhelmed trying to handle these tasks one by one. But a GPU, with its thousands of simple cores, can process huge batches of vertices and pixels all at once.</p><p>This is why we write shaders for the GPU. We are providing the “recipe” for the assembly line workers. The GPU’s architecture is not just “more cores”; it’s a completely different philosophy of computation, one that is perfectly and beautifully matched to the massive, repetitive, and parallel nature of computer graphics.</p><h2 id=\"the-rendering-pipeline-in-detail\">The Rendering Pipeline in Detail</h2>\n<p>Let’s zoom in on the VFX studio’s assembly line. Each stage has a specific responsibility, taking a particular kind of data as input and producing a new kind of data for the next stage to work on.</p><h3 id=\"stage-1-the-application-stage-cpu---the-directors-brief\">Stage 1: The Application Stage (CPU - The Director’s Brief)</h3>\n<p>This stage isn’t on the GPU at all - it’s your Bevy application running on the CPU. Think of it as the “pre-production” step where the director prepares the detailed brief. Before any rendering can happen, your application needs to tell the GPU everything it needs to know about the world for the upcoming frame. Bevy’s renderer orchestrates this for you.</p><p>For every frame, Bevy traverses your scene’s Entity-Component-System (ECS) world and gathers all the necessary information:</p><pre><code class=\"language-rust\">// You write this in Bevy, describing the &quot;what&quot; and &quot;where&quot;\ncommands.spawn((\n Mesh3d(meshes.add(Sphere::new(1.0))),\n MeshMaterial3d(materials.add(my_custom_material)),\n));\n</code></pre>\n<p>From code like this, Bevy assembles the “shot list”:</p><ul>\n<li><strong>What to draw</strong>: A list of meshes (the sphere’s vertices and triangles).</li>\n<li><strong>How to draw it</strong>: The material to use and its properties (colors, textures).</li>\n<li><strong>Where it is</strong>: The object’s world position, rotation, and scale (the Transform).</li>\n<li><strong>From where to view it</strong>: The camera’s position and perspective settings.</li>\n</ul>\n<p>The final output of this stage is a highly-organized package of data and commands, which Bevy then sends over to the GPU to begin the actual rendering process.</p><h3 id=\"stage-2-the-vertex-shader-gpu---the-layout-artists\">Stage 2: The Vertex Shader (GPU - The Layout Artists)</h3>\n<p>This is the <strong>first programmable stage</strong> on the GPU, where your first piece of WGSL code runs. The vertex shader’s fundamental job is to answer one question for every single vertex of a mesh: <strong>“Where on the screen does this vertex end up?”</strong></p><ul>\n<li><strong>Input</strong>: It receives the data for a <strong>single vertex</strong> at a time (its position in local model space, its normal vector, its UV coordinates, etc.).</li>\n<li><strong>The Job</strong>: Its one mandatory task is to perform mathematical operations (usually matrix multiplications) to transform the vertex’s 3D position into a final 4D “clip space” position. This clip space coordinate is what the GPU hardware needs to figure out the 2D location on your monitor.</li>\n<li><strong>Output</strong>: It must output that final clip space position. It can also pass along any other data it received or calculated (like colors, normals, or UVs) to be used later by the fragment shader.</li>\n</ul>\n<p>Here’s a conceptual view of what your WGSL code will do:</p><pre><code class=\"language-wgsl\">@vertex\nfn vertex(input: VertexInput) -&gt; VertexOutput {\n    var output: VertexOutput;\n\n    // The primary job: Transform the 3D local position into a final 2D screen position.\n    output.position = project_to_screen(view_matrix * model_matrix * input.position);\n\n    // A secondary job: Pass necessary data to the next stage.\n    // Here, we&#39;re just passing the vertex&#39;s normal along for lighting calculations later.\n    output.normal = input.normal;\n    return output;\n}\n</code></pre>\n<p><strong>Key Insight</strong>: Because this shader runs on every vertex, it gives you the power to manipulate the shape and position of your geometry in real-time. This is not just about moving objects around (which is best done by changing the Transform in Bevy); it’s about deforming the mesh itself. This is how you create dynamic effects like:</p><ul>\n<li>Waving flags</li>\n<li>Rippling water surfaces</li>\n<li>Procedurally animated grass swaying in the wind</li>\n</ul>\n<h3 id=\"stage-3-the-rasterizer-gpu---automatic-hardware\">Stage 3: The Rasterizer (GPU - Automatic Hardware)</h3>\n<p>This stage is a piece of dedicated, non-programmable hardware on the GPU. It’s an automatic, incredibly fast process that you don’t write code for. The rasterizer takes the processed vertices from the vertex shader (three at a time to form a triangle) and figures out which pixels on the screen that triangle covers.</p><p>For every single pixel it covers, it generates a <strong>“fragment.”</strong> A fragment is a “potential pixel” - it contains all the information needed to calculate a final color.</p><p>This is also where the magic of <strong>interpolation</strong> happens. The rasterizer looks at the data you passed out of the vertex shader for each of the triangle’s three vertices and smoothly blends it across the surface of the triangle for each fragment.</p><p>Think of it like this:</p><figure class=\"post__image\"><img src=\"/media/files/1.1%20-%20figure%20-%20Rasterizer.png\" alt=\"rasterizer\" data-is-external-image=\"true\"></figure><ul>\n<li>A fragment near the top will receive a reddish color.</li>\n<li>A fragment on the left edge will get a purplish color (red + blue).</li>\n<li>A fragment right in the middle will get a muddy, grayish color, which is the mathematical average of red, green, and blue.</li>\n</ul>\n<p>The rasterizer does this for every single piece of data you passed along - colors, UV coordinates, normals, etc. The output is a massive stream of fragments, each one “pre-loaded” with its own unique, interpolated data, ready to be colored.</p><h3 id=\"stage-4-the-fragment-shader-gpu---the-rendering-artists\">Stage 4: The Fragment Shader (GPU - The Rendering Artists)</h3>\n<p>This is the <strong>second programmable stage</strong>, and it’s where most of the visual artistry happens. The fragment shader’s job is to answer one simple question for every single fragment generated by the rasterizer: <strong>“What color is this pixel?”</strong></p><ul>\n<li><strong>Input</strong>: It receives the interpolated data for a <strong>single fragment</strong>. This includes its position on the screen and the smoothly blended values (like normals and UVs) that were passed from the vertex shader.</li>\n<li><strong>The Job</strong>: To use this input data to perform calculations and return a single, final color.</li>\n<li><strong>Output</strong>: It must output a <code>vec4&lt;f33&gt;</code> representing an RGBA color. This is the color that will be written to the screen (assuming it passes final tests like depth testing).</li>\n</ul>\n<p>Here’s a conceptual view of what your WGSL code will do:</p><pre><code class=\"language-wgsl\">@fragment\nfn fragment(input: FragmentInput) -&gt; @location(0) vec4&lt;f32&gt; {\n    // The input data (e.g., input.normal) has already been smoothly interpolated for us.\n    // We can use it to calculate lighting for this specific pixel.\n    let lighting = calculate_light(input.normal, light_direction);\n\n    // We could also sample a texture using the interpolated UVs.\n    let surface_color = sample_texture(input.uv);\n\n    // Combine them to get the final color.\n    let final_color = surface_color * lighting;\n    return vec4&lt;f32&gt;(final_color, 1.0); // Return the final RGBA value\n}\n</code></pre>\n<p><strong>Key Insight</strong>: The fragment shader runs for potentially millions of pixels every frame. This is your chance to define the appearance of your object’s surface with incredible detail. This is where you:</p><ul>\n<li>Apply lighting calculations to create highlights and shadows.</li>\n<li>Sample textures to give a surface detail and color.</li>\n<li>Create procedural patterns like stripes, checkerboards, or noise.</li>\n<li>Implement special effects like glowing, outlines, or distortion.</li>\n</ul>\n<h2 id=\"the-coordinate-space-journey\">The Coordinate Space Journey</h2>\n<p>One of the most initially confusing, but ultimately powerful, concepts in graphics programming is the journey a vertex takes through different <strong>coordinate spaces</strong>. Each space is a different frame of reference, like describing a location from a different point of view. The vertex shader’s main job is to transform a vertex from one space to the next, like a series of conversions, until it lands in the right spot on the screen.</p><p>Think of it like giving directions to a friend:</p><ol>\n<li>“The book is on the second shelf of the bookcase.” (<strong>Local Space</strong>: The position is relative to the bookcase).</li>\n<li>“The bookcase is against the north wall of the living room.” (<strong>World Space</strong>: Now the bookcase’s position is relative to the entire house).</li>\n<li>“Stand in the doorway and look towards the fireplace.” (<strong>View Space</strong>: Now everything is described from your friend’s point of view).</li>\n<li>“The book you’re looking for should be in the upper-left part of your vision.” (<strong>Clip Space</strong>: This is what’s in their field of view).</li>\n</ol>\n<p>In 3D graphics, we perform these transformations using matrix mathematics.</p><p><strong>Note</strong>: Don’t worry if the matrix math looks intimidating right now. We have a dedicated chapter later that explains how matrices work. For now, just focus on the purpose of each transformation - what question it answers.</p><h3 id=\"1-local-space-or-model-space\">1. Local Space (or Model Space)</h3>\n<p><strong>The Question:</strong> “What does this object look like by itself?”</p><p>This is the object’s blueprint. When an artist creates a 3D model of a car, they don’t care where it will be in your game world. They model it at the center of its own universe, the origin <code>(0, 0, 0)</code>. The coordinates of every vertex are relative only to the car’s own center point.</p><pre><code class=\"language-plaintext\">A car&#39;s front-right tire vertex in Local Space might be:\n(0.8, 0.3, 1.5)\n</code></pre>\n<h3 id=\"2-world-space\">2. World Space</h3>\n<p><strong>The Question:</strong> “Where is this object in the game world?”</p><p>This is the shared, global coordinate system of your entire scene. It’s the common frame of reference where all your objects, lights, and the camera coexist. When you give an entity a Transform in Bevy, you are defining its position, rotation, and scale within this World Space.</p><pre><code class=\"language-rust\">// This Transform moves the object from its local origin to a specific spot in the world.\nTransform::from_xyz(10.0, 0.0, -20.0)\n</code></pre>\n<p>The <strong>Model Matrix</strong>, which Bevy derives from this <code>Transform</code>, is the mathematical tool that converts vertices from <strong>Local Space</strong> to <strong>World Space</strong>. Your vertex shader applies it to every vertex.</p><pre><code class=\"language-plaintext\">Local Position × Model Matrix = World Position\n</code></pre>\n<h3 id=\"3-view-space-or-camera-space\">3. View Space (or Camera Space)</h3>\n<p><strong>The Question:</strong> “How does the world look from the camera’s perspective?”</p><p>Once everything is placed in the world, we need to view it. To make the math simpler for the next step, we transform the entire world so that the camera is at the origin <code>(0, 0, 0)</code> and looking down a specific axis (typically negative Z). Everything in the world is now positioned relative to the camera. An object in front of the camera will have a negative Z coordinate, an object to the camera’s left will have a negative X, and so on.</p><p>The <strong>View Matrix</strong> performs this transformation. It’s calculated from the camera’s own world-space transform.</p><pre><code class=\"language-plaintext\">World Position × View Matrix = View Position\n</code></pre>\n<h3 id=\"4-clip-space\">4. Clip Space</h3>\n<p><strong>The Question:</strong> “Is this vertex inside the viewable area, and if so, where?”</p><p>This is the final and most abstract space that the vertex shader is responsible for creating. It’s a standardized, cube-like volume that represents everything the camera can see. The transformation into this space, performed by the <strong>Projection Matrix</strong>, does two magical things:</p><ol>\n<li><strong>It applies perspective.</strong> It mathematically squishes the 3D scene so that objects farther away from the camera appear smaller than objects that are closer. This is what creates the illusion of depth.</li>\n<li><strong>It normalizes the coordinates.</strong> Everything that will be visible on screen is mapped into a neat box where the X and Y coordinates range from -1 to 1. The Z coordinate is also remapped (usually to a <code>[0, 1]</code> range) to represent depth.</li>\n</ol>\n<p>The GPU now has a simple job: any vertex with X or Y coordinates outside of this <code>[-1, 1]</code> range is “clipped” and discarded, as it is off-screen. The Z coordinate will be used in a later stage for depth testing (figuring out if one object is in front of another).</p><pre><code class=\"language-plaintext\">View Position × Projection Matrix = Clip Position\n</code></pre>\n<p>The mandatory output of your vertex shader is this final Clip Space position.</p><h3 id=\"5-screen-space\">5. Screen Space</h3>\n<p><strong>The Question:</strong> “Which specific pixel on my monitor does this correspond to?”</p><p>This final step is handled <strong>automatically by the GPU</strong> after the vertex shader is done. The hardware takes the <code>[-1, 1]</code> Clip Space coordinates and maps them to the actual pixel coordinates of your window (e.g., from <code>(0, 0)</code> in the top-left to <code>(1920, 1080)</code> in the bottom-right). This is not something you calculate in your shaders; it’s the final output of the fixed-function part of the pipeline before the fragment shader runs.</p><h2 id=\"putting-it-all-together-the-life-of-a-single-vertex\">Putting It All Together: The Life of a Single Vertex</h2>\n<p>Let’s trace the complete life of a single vertex, from its creation in a modeling tool to its final appearance as a colored pixel on your screen. We’ll follow a vertex at the very top of a sphere model.</p><h3 id=\"1-the-blueprint-cpu---local-space\">1. The Blueprint (CPU - Local Space)</h3>\n<p>It begins its life in a 3D modeling program. An artist defines a sphere, and our vertex is created at the very top. Relative to the sphere’s own center, its position is simply (0.0, 1.0, 0.0). This is its <strong>Local Space</strong> position. This data is loaded into Bevy as part of a Mesh asset.</p><h3 id=\"2-setting-the-scene-cpu---the-directors-brief\">2. Setting the Scene (CPU - The Director’s Brief)</h3>\n<p>Your Bevy application decides where this sphere belongs in the game world. You assign it a <code>Transform</code> to place it, for example, at world coordinates <code>(5.0, 2.0, -3.0)</code>. The CPU doesn’t move the vertex itself; instead, it calculates a <strong>Model Matrix</strong> from this transform and packages it up, ready to be sent to the GPU’s VFX studio.</p><h3 id=\"3-the-great-transformation-gpu---vertex-shader\">3. The Great Transformation (GPU - Vertex Shader)</h3>\n<p>Now the director’s brief is uploaded to the GPU, and our programmable <strong>Vertex Shader</strong> takes over. This is where the “Layout Artists” get to work. The shader receives our vertex’s original local position, <code>(0, 1, 0)</code>, along with the Model, View, and Projection matrices. It then performs the crucial sequence of multiplications to find the vertex’s final on-screen position:</p><ul>\n<li><strong>To World Space</strong>: The shader multiplies the local position by the Model Matrix. This moves the vertex into the shared <strong>World Space</strong>. Our vertex at <code>(0, 1, 0)</code> is now effectively at <code>(5.0, 3.0, -3.0)</code> in the game world (position + model’s height).</li>\n<li><strong>To View Space</strong>: Next, it multiplies the new world position by the View Matrix. This transforms the vertex into <strong>View Space</strong>, making its coordinates relative to the camera’s perspective. Its position might now be something like <code>(-2.0, 1.0, -5.0)</code>, meaning it’s slightly to the camera’s left, above its center, and some distance in front of it.</li>\n<li><strong>To Clip Space</strong>: Finally, it multiplies the view position by the Projection Matrix. This applies perspective and transforms the vertex into the final, required <strong>Clip Space</strong>. The position might now be <code>(-0.4, 0.2, 0.8)</code>. This tells the GPU the vertex is on-screen (since X and Y are between <code>-1</code> and <code>1</code>) and provides its depth. This <code>vec4</code> is the mandatory output of the vertex shader.</li>\n</ul>\n<p>Simultaneously, the vertex shader also prepares any other data needed for coloring, like the vertex’s color or normal vector, and passes it along.</p><h3 id=\"4-the-triangle-factory-gpu---rasterizer\">4. The Triangle Factory (GPU - Rasterizer)</h3>\n<p>The vertex, now just a point in Clip Space, is grouped by the GPU with two other processed vertices to form a triangle. The hardware <strong>Rasterizer</strong> takes over, calculating exactly which screen pixels this triangle covers. For each covered pixel, it generates a “fragment” and <strong>interpolates</strong> all the data that the vertex shaders passed out (like colors or UVs), creating a smooth gradient of values across the triangle’s face.</p><h3 id=\"5-the-coloring-book-gpu---fragment-shader\">5. The Coloring Book (GPU - Fragment Shader)</h3>\n<p>A single fragment, born from the rasterizer, arrives at our programmable <strong>Fragment Shader</strong>. Now the “Rendering Artists” do their job. The fragment carries its own unique, interpolated data (e.g., a color that is a blend of the three corner vertices’ colors). The fragment shader’s sole job is to use this information to calculate a final RGBA color. It might sample a texture, calculate lighting, or perform any number of other operations.</p><h3 id=\"6-the-final-pixel-gpu---output-merger\">6. The Final Pixel (GPU - Output Merger)</h3>\n<p>The fragment shader outputs its calculated color. This color, along with the fragment’s depth, is sent to the final hardware stage. The GPU performs a <strong>depth test</strong> to see if this fragment is in front of whatever is already on the screen at that pixel. If it is, its color is written to the framebuffer, becoming one of the millions of pixels that form the final image you see. Our vertex has completed its journey.</p><h2 id=\"a-mental-model-for-your-shaders\">A Mental Model for Your Shaders</h2>\n<p>The rendering pipeline can seem complex, but by holding on to our “Director and VFX Studio” analogy, we can assign a clear, relatable job to each programmable stage.</p><h3 id=\"1-the-vertex-shader-the-vfx-layout-artist\">1. The Vertex Shader: The VFX Layout Artist</h3>\n<p>Your WGSL code in the vertex shader provides the instructions for the layout artists at the VFX studio.</p><table>\n<thead>\n<tr>\n<th>Analogy</th>\n<th>Role</th>\n<th>Shader Code Focus</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Staging the scene for the camera.</strong></td>\n<td>Your job is to take the 3D models (defined in their own local space) and <strong>place them correctly in the world and frame them perfectly in the camera’s shot.</strong></td>\n<td><strong>Transformation.</strong> You use matrix math to move each vertex of a model from its origin to its final position relative to the camera’s view. You can also dynamically move vertices here to create animations like waving flags or rippling water.</td>\n</tr>\n<tr>\n<td><strong>Defining the final composition.</strong></td>\n<td>You must output the final projected position of each vertex. This is the main deliverable for this stage.</td>\n<td><code>output.position = projection * view * model * local_pos;</code></td>\n</tr>\n<tr>\n<td><strong>Prepping for the colorists.</strong></td>\n<td>You pass along any surface information that the next team will need, like texture coordinates (uv) or which way the surface is facing (normal).</td>\n<td><code>output.world_normal = ..., output.uv = ...</code></td>\n</tr>\n</tbody></table>\n<h3 id=\"2-the-rasterizer-the-digital-render-farm\">2. The Rasterizer: The Digital Render Farm</h3>\n<p>This is an automated, non-programmable hardware stage. You don’t write code for it, but you need to know what it does.</p><table>\n<thead>\n<tr>\n<th>Analogy</th>\n<th>Role</th>\n<th>Shader Code Focus</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Automated rendering setup.</strong></td>\n<td>The GPU’s hardware takes the 3D triangles you’ve positioned in the previous step…</td>\n<td><strong>None.</strong> This is a fixed, non-programmable step.</td>\n</tr>\n<tr>\n<td><strong>…and projects them onto a 2D grid.</strong></td>\n<td>The hardware determines exactly which pixels on the screen are covered by each triangle. For each covered pixel, it creates a “fragment” and <strong>interpolates</strong> (smoothly blends) the data from the triangle’s corners.</td>\n<td>A fragment in the middle of a triangle gets a perfectly blended uv coordinate and normal vector, ready for the next stage.</td>\n</tr>\n</tbody></table>\n<h3 id=\"3-the-fragment-shader-the-vfx-coloring--lighting-artist\">3. The Fragment Shader: The VFX Coloring &amp; Lighting Artist</h3>\n<p>Your WGSL code in the fragment shader provides the instructions for the massive team of coloring and lighting artists.</p><table>\n<thead>\n<tr>\n<th>Analogy</th>\n<th>Role</th>\n<th>Shader Code Focus</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>Painting one pixel at a time.</strong></td>\n<td>Your job is to look at a single, uncolored pixel (a fragment) and <strong>decide what its final color should be.</strong> This is where all the visual artistry happens.</td>\n<td><strong>Color Calculation.</strong> You have complete control over the pixel’s final RGBA value.</td>\n</tr>\n<tr>\n<td><strong>Using the prepped materials.</strong></td>\n<td>You use the interpolated data from the previous stage to perform your work.</td>\n<td><code>return vec4&lt;f32&gt;(final_color, alpha);</code></td>\n</tr>\n<tr>\n<td><strong>Applying textures and lighting.</strong></td>\n<td>You can sample <strong>textures</strong> using the interpolated uv coordinates and use the interpolated normal vector to calculate realistic <strong>lighting</strong> and shadows.</td>\n<td><code>textureSample(...)</code>, <code>dot(normal, light_dir)</code></td>\n</tr>\n</tbody></table>\n<hr>\n<h2 id=\"complete-example-visualizing-the-pipeline\">Complete Example: Visualizing the Pipeline</h2>\n<p>Theory is essential, but seeing is believing. To make these abstract concepts concrete, we’ll build a simple, interactive shader in Bevy. This shader won’t create a realistic object; instead, it will act as a diagnostic tool, allowing us to “see” the data at different stages of the pipeline.</p><p><strong>A Note Before We Begin:</strong> You will see new WGSL syntax (@location, @group, etc.) and Bevy patterns (AsBindGroup, MaterialPlugin) in the code below. <strong>Do not worry about understanding every line right now.</strong> We will break down all of these concepts in detail in the upcoming articles.</p><p>The goal of this example is to <strong>observe the visual output</strong> of each mode and connect it back to the high-level pipeline concepts we just learned:</p><ul>\n<li>How data is <strong>interpolated</strong> across a surface (the smooth normal colors).</li>\n<li>How the fragment shader runs for <strong>every pixel</strong> (the sharp checkerboard).</li>\n<li>How data from the <strong>vertex stage</strong> is used in the <strong>fragment stage</strong> (the height gradient).</li>\n</ul>\n<p>Focus on the “what you’re seeing” part, and treat the code as a preview of what you’ll soon master.</p><h3 id=\"our-goal\">Our Goal</h3>\n<p>We will create a custom material for a sphere that can cycle through three different visualization modes by pressing a key. Each mode will highlight a different core concept of the rendering pipeline that we’ve just discussed.</p><h3 id=\"what-this-project-demonstrates\">What This Project Demonstrates</h3>\n<ul>\n<li><strong>Data Flow and Interpolation:</strong> How data (like normal vectors) passed from the vertex shader is smoothly interpolated by the rasterizer before reaching the fragment shader.</li>\n<li><strong>Per-Fragment Processing:</strong> Proof that the fragment shader runs independently for every single pixel, allowing it to create complex patterns based on a fragment’s world position.</li>\n<li><strong>Vertex Data in Fragment Shaders:</strong> How to use data prepared by the vertex shader (like the final world position) to drive calculations in the fragment shader.</li>\n</ul>\n<h3 id=\"the-shader-assetsshadersdebug_pipelinewgsl\">The Shader (<code>assets/shaders/debug_pipeline.wgsl</code>)</h3>\n<p>This single WGSL file contains both our vertex and fragment shaders. The key element is the material.mode uniform, a number we can change from our Rust code to switch the logic inside the fragment shader.</p><ul>\n<li>The <strong>vertex shader</strong> is standard: it transforms the vertex position into clip space and also passes the vertex’s world position and world normal along to the fragment stage.</li>\n<li>The <strong>fragment shader</strong> uses an <code>if/else if</code> chain based on material.mode to decide how to color the current pixel.</li>\n</ul>\n<pre><code class=\"language-wgsl\">#import bevy_pbr::mesh_functions\n#import bevy_pbr::view_transformations::position_world_to_clip\n#import bevy_pbr::forward_io::VertexOutput\n\nstruct DebugMaterial {\n    mode: u32,\n}\n\n@group(2) @binding(0)\nvar&lt;uniform&gt; material: DebugMaterial;\n\n@vertex\nfn vertex(\n    @builtin(instance_index) instance_index: u32,\n    @location(0) position: vec3&lt;f32&gt;,\n    @location(1) normal: vec3&lt;f32&gt;,\n) -&gt; VertexOutput {\n    var out: VertexOutput;\n    \n    // Get the model transformation matrix\n    let world_from_local = mesh_functions::get_world_from_local(instance_index);\n    \n    // Transform position to world space\n    let world_position = mesh_functions::mesh_position_local_to_world(\n        world_from_local,\n        vec4&lt;f32&gt;(position, 1.0)\n    );\n    \n    // Transform to clip space (final vertex shader output)\n    out.position = position_world_to_clip(world_position.xyz);\n    \n    // Transform normal to world space\n    out.world_normal = mesh_functions::mesh_normal_local_to_world(\n        normal,\n        instance_index\n    );\n    \n    // Pass world position to fragment shader\n    out.world_position = world_position;\n    \n    return out;\n}\n\n@fragment\nfn fragment(in: VertexOutput) -&gt; @location(0) vec4&lt;f32&gt; {\n    // Mode 0: Show normals (demonstrates interpolation between vertices)\n    if material.mode == 0u {\n        // Normals range from -1 to 1, convert to 0-1 for RGB color\n        // Red = X direction, Green = Y direction, Blue = Z direction\n        let color = (in.world_normal + 1.0) * 0.5;\n        return vec4&lt;f32&gt;(color, 1.0);\n    }\n    \n    // Mode 1: Checkerboard pattern (demonstrates per-pixel fragment shader work)\n    if material.mode == 1u {\n        // Create a 3D checkerboard pattern\n        let scale = 3.0;\n        let x = i32(floor(in.world_position.x * scale));\n        let y = i32(floor(in.world_position.y * scale));\n        let z = i32(floor(in.world_position.z * scale));\n        \n        // Use bitwise AND to alternate between 0 and 1\n        let checker = (x + y + z) &amp; 1;\n        \n        if checker == 0 {\n            return vec4&lt;f32&gt;(0.9, 0.9, 0.9, 1.0); // Light gray\n        } else {\n            return vec4&lt;f32&gt;(0.2, 0.2, 0.8, 1.0); // Blue\n        }\n    }\n    \n    // Mode 2: Height-based gradient (demonstrates math in fragment shader)\n    if material.mode == 2u {\n        // Color based on Y position (height) in world space\n        // Map from -2 to 2 range to 0-1 range for color\n        let height = (in.world_position.y + 2.0) / 4.0;\n        let color = vec3&lt;f32&gt;(height, 0.5, 1.0 - height);\n        return vec4&lt;f32&gt;(color, 1.0);\n    }\n    \n    // Default: Solid color\n    return vec4&lt;f32&gt;(1.0, 0.0, 0.0, 1.0);\n}\n</code></pre>\n<h3 id=\"the-rust-material-srcmaterialsdebug_pipeliners\">The Rust Material (<code>src/materials/debug_pipeline.rs</code>)</h3>\n<p>This is the Rust-side definition of our material. It’s a simple struct that mirrors the DebugMaterial struct in our shader, allowing Bevy’s rendering engine to send our chosen mode value to the GPU.</p><pre><code class=\"language-rust\">use bevy::prelude::*;\nuse bevy::render::render_resource::{AsBindGroup, ShaderRef};\n\n#[derive(Asset, TypePath, AsBindGroup, Debug, Clone)]\npub struct DebugPipelineMaterial {\n    #[uniform(0)]\n    pub mode: u32,\n}\n\nimpl Material for DebugPipelineMaterial {\n    fn fragment_shader() -&gt; ShaderRef {\n        &quot;shaders/debug_pipeline.wgsl&quot;.into()\n    }\n\n    fn vertex_shader() -&gt; ShaderRef {\n        &quot;shaders/debug_pipeline.wgsl&quot;.into()\n    }\n}\n</code></pre>\n<p>Don’t forget to add it to <code>src/materials/mod.rs</code>:</p><pre><code class=\"language-rust\">// ... other materials\npub mod debug_pipeline;\n</code></pre>\n<h3 id=\"the-demo-module-srcdemosdebug_pipeliners\">The Demo Module (<code>src/demos/debug_pipeline.rs</code>)</h3>\n<p>This Rust module sets up our Bevy scene. It spawns a sphere with our custom <code>DebugPipelineMaterial</code>, adds a camera and light, and sets up the UI text. Most importantly, it contains the <code>cycle_debug_mode</code> system, which listens for the spacebar press and updates the mode field on our material, triggering the change in the shader.</p><pre><code class=\"language-rust\">use crate::materials::debug_pipeline::DebugPipelineMaterial;\nuse bevy::prelude::*;\n\npub fn run() {\n    App::new()\n        .add_plugins(DefaultPlugins)\n        .add_plugins(MaterialPlugin::&lt;DebugPipelineMaterial&gt;::default())\n        .add_systems(Startup, setup)\n        .add_systems(Update, (rotate_camera, cycle_debug_mode))\n        .run();\n}\n\nfn setup(\n    mut commands: Commands,\n    mut meshes: ResMut&lt;Assets&lt;Mesh&gt;&gt;,\n    mut materials: ResMut&lt;Assets&lt;DebugPipelineMaterial&gt;&gt;,\n) {\n    // Spawn a sphere with our debug material (better for showing interpolation)\n    commands.spawn((\n        Mesh3d(meshes.add(Sphere::new(1.0))),\n        MeshMaterial3d(materials.add(DebugPipelineMaterial { mode: 0 })),\n    ));\n\n    // Light\n    commands.spawn((\n        PointLight {\n            shadows_enabled: true,\n            ..default()\n        },\n        Transform::from_xyz(4.0, 8.0, 4.0),\n    ));\n\n    // Camera\n    commands.spawn((\n        Camera3d::default(),\n        Transform::from_xyz(-2.5, 4.5, 9.0).looking_at(Vec3::ZERO, Vec3::Y),\n    ));\n\n    // UI to show current mode\n    commands.spawn((\n        Text::new(&quot;Press SPACE to cycle debug modes\\nMode 0: Normals (shows interpolation)&quot;),\n        Node {\n            position_type: PositionType::Absolute,\n            top: Val::Px(10.0),\n            left: Val::Px(10.0),\n            ..default()\n        },\n    ));\n}\n\nfn rotate_camera(time: Res&lt;Time&gt;, mut camera_query: Query&lt;&amp;mut Transform, With&lt;Camera3d&gt;&gt;) {\n    for mut transform in camera_query.iter_mut() {\n        let radius = 9.0;\n        let angle = time.elapsed_secs() * 0.5;\n        transform.translation.x = angle.cos() * radius;\n        transform.translation.z = angle.sin() * radius;\n        transform.look_at(Vec3::ZERO, Vec3::Y);\n    }\n}\n\nfn cycle_debug_mode(\n    keyboard: Res&lt;ButtonInput&lt;KeyCode&gt;&gt;,\n    mut materials: ResMut&lt;Assets&lt;DebugPipelineMaterial&gt;&gt;,\n    mut text_query: Query&lt;&amp;mut Text&gt;,\n) {\n    if keyboard.just_pressed(KeyCode::Space) {\n        for (_, material) in materials.iter_mut() {\n            material.mode = (material.mode + 1) % 3;\n\n            for mut text in text_query.iter_mut() {\n                **text = match material.mode {\n                    0 =&gt; &quot;Press SPACE to cycle debug modes\\nMode 0: Normals (shows interpolation)&quot;.to_string(),\n                    1 =&gt; &quot;Press SPACE to cycle debug modes\\nMode 1: Checkerboard (per-pixel processing)&quot;.to_string(),\n                    2 =&gt; &quot;Press SPACE to cycle debug modes\\nMode 2: Height Gradient (fragment math)&quot;.to_string(),\n                    _ =&gt; &quot;Unknown mode&quot;.to_string(),\n                };\n            }\n        }\n    }\n}\n</code></pre>\n<p>Don’t forget to add it to <code>src/demos/mod.rs</code>:</p><pre><code class=\"language-rust\">// ... other demoss\npub mod debug_pipeline;\n</code></pre>\n<p>And register it in <code>src/main.rs</code>:</p><pre><code class=\"language-rust\">Demo {\n    number: &quot;1.1&quot;,\n    title: &quot;Understanding the Graphics Pipeline&quot;,\n    run: demos::debug_pipeline::run,\n},\n</code></pre>\n<h3 id=\"running-the-demo\">Running the Demo</h3>\n<p>When you run the project, you will see a sphere. Pressing the spacebar will cycle through the three different debug visualizations, each revealing a different aspect of the pipeline’s inner workings.</p><h4 id=\"controls\">Controls</h4>\n<table>\n<thead>\n<tr>\n<th>Control</th>\n<th>Action</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>SPACE</strong></td>\n<td>Cycle to the next visualization mode (0 -&gt; 1 -&gt; 2 -&gt; 0).</td>\n</tr>\n</tbody></table>\n<h4 id=\"what-youre-seeing\">What You’re Seeing</h4>\n<figure class=\"post__image\"><img src=\"/media/files/1.1%20-%20screenshot%20-%201.png\" alt=\"screenshot 1\" data-is-external-image=\"true\"></figure>\n<figure class=\"post__image\"><img src=\"/media/files/1.1%20-%20screenshot%20-%202.png\" alt=\"screenshot 2\" data-is-external-image=\"true\"></figure>\n<figure class=\"post__image\"><img src=\"/media/files/1.1%20-%20screenshot%20-%203.png\" alt=\"screenshot 3\" data-is-external-image=\"true\"></figure><table>\n<thead>\n<tr>\n<th>Mode</th>\n<th>Description</th>\n<th>What It Proves</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>0 - Normals</strong></td>\n<td>The sphere is colored based on the direction its surface is facing. Red points right (+X), Green points up (+Y), and Blue points forward (+Z). You see smooth gradients of color across the entire surface.</td>\n<td>This demonstrates <strong>interpolation</strong>. The normals are defined only at the vertices, but the rasterizer smoothly blends them between those points, giving every single pixel its own unique normal vector to use for coloring.</td>\n</tr>\n<tr>\n<td><strong>1 - Checkerboard</strong></td>\n<td>The sphere is covered in a 3D checkerboard pattern that appears fixed in the world as the sphere rotates through it. The pattern is sharp and blocky.</td>\n<td>This demonstrates <strong>per-fragment processing</strong>. The fragment shader calculates which color to be (light gray or blue) for every single pixel independently, based on that pixel’s position in world space.</td>\n</tr>\n<tr>\n<td><strong>2 - Height Gradient</strong></td>\n<td>The sphere is colored with a gradient based on its height in the world. The bottom is magenta, and the top is cyan.</td>\n<td>This demonstrates using <strong>vertex shader data in the fragment shader</strong>. The vertex shader calculates the world_position for each vertex. The rasterizer interpolates it, and the fragment shader uses the Y-component of that position to calculate a color.</td>\n</tr>\n</tbody></table>\n<h2 id=\"key-takeaways\">Key Takeaways</h2>\n<p>This chapter covered a lot of ground. Before moving on, take a moment to solidify these five core concepts. They are the foundation for everything that follows.</p><ol>\n<li><strong>The Pipeline is a CPU-to-GPU Process.</strong><br> Rendering is a collaboration. Your Bevy code on the CPU acts as the <strong>Director</strong>, preparing the scene’s data (meshes, materials, transforms). It then hands this “shot list” to the GPU, a specialized <strong>VFX Studio</strong> that executes the rendering process through a hardware assembly line.</li>\n<li><strong>Shaders are Your Instructions for the VFX Artists.</strong><br> You cannot change the hardware pipeline itself, but you can write small, highly focused programs called <strong>shaders</strong> that run at critical, programmable stages. The GPU’s massively parallel architecture executes your shader code for millions of vertices and pixels per second, which is what makes real-time 3D graphics possible.</li>\n<li><strong>The Vertex Shader’s Job is to POSITION Geometry.</strong><br> This is your “Layout Artist” stage. The vertex shader runs once for every vertex in your mesh. Its primary responsibility is to take that vertex’s 3D position from the original model and transform it through a series of coordinate spaces until it has its final, correct position on the 2D screen.</li>\n<li><strong>The Fragment Shader’s Job is to COLOR Pixels.</strong><br> This is your “Coloring &amp; Lighting Artist” stage. After the hardware rasterizer determines which pixels a triangle covers, the fragment shader runs once for every single one of those “fragments.” Its sole responsibility is to calculate and return the final RGBA color for that specific spot on the screen. This is where you apply textures, lighting, and visual effects.</li>\n<li><strong>Data Flows and is Interpolated from Vertex to Fragment.</strong><br> The two shaders are connected. The vertex shader can pass data (like UV coordinates or normal vectors) to the next stage. The hardware <strong>Rasterizer</strong> automatically <strong>interpolates</strong> (smoothly blends) this data across the face of the triangle, making a unique version of it available to the fragment shader for every single pixel.</li>\n</ol>\n<h2 id=\"whats-next\">What’s Next?</h2>\n<p>You now have the essential mental model for the rendering pipeline - you understand where your shader code runs and the specific job of each stage. With this “map” in hand, we are finally ready to learn the language of the GPU’s artists themselves.</p><p>In the next article, we will dive into the fundamental building blocks of the WGSL language: its data types and variables. You’ll learn how to represent positions, colors, and transformations in your code using scalars, vectors, and matrices.</p><p><em>Next up:</em> <a href=\"https://hexbee.hashnode.dev/12-wgsl-fundamentals-data-types-and-variables\"><strong><em>1.2 - WGSL Fundamentals - Data Types &amp; Variables</em></strong></a></p><hr>\n<h2 id=\"quick-reference\">Quick Reference</h2>\n<p>A summary of the core concepts for quick lookup.</p><h3 id=\"the-pipeline-stages--their-jobs\">The Pipeline Stages &amp; Their Jobs</h3>\n<table>\n<thead>\n<tr>\n<th>Stage</th>\n<th>Analogy</th>\n<th>Role (What it does)</th>\n<th>Programmable?</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>1. Application (CPU)</strong></td>\n<td>The Director</td>\n<td>Prepares all scene data: meshes, materials, transforms, camera info.</td>\n<td>Yes (Rust)</td>\n</tr>\n<tr>\n<td><strong>2. Vertex Shader</strong></td>\n<td>The Layout Artist</td>\n<td>Runs <strong>per-vertex</strong> to calculate its final on-screen position (in Clip Space).</td>\n<td><strong>Yes (WGSL)</strong></td>\n</tr>\n<tr>\n<td><strong>3. Rasterizer</strong></td>\n<td>The Render Farm</td>\n<td><strong>Automatic hardware</strong> step that turns 3D triangles into a 2D grid of fragments.</td>\n<td>No</td>\n</tr>\n<tr>\n<td><strong>4. Fragment Shader</strong></td>\n<td>The Coloring Artist</td>\n<td>Runs <strong>per-fragment</strong> to calculate its final RGBA color.</td>\n<td><strong>Yes (WGSL)</strong></td>\n</tr>\n<tr>\n<td><strong>5. Output Merger</strong></td>\n<td>The Final Print</td>\n<td><strong>Automatic hardware</strong> step that performs depth tests and writes the final color.</td>\n<td>No</td>\n</tr>\n</tbody></table>\n<h3 id=\"the-coordinate-space-journey-1\">The Coordinate Space Journey</h3>\n<p>This is the required path a single vertex position takes through the Vertex Shader.</p><pre><code class=\"language-plaintext\">Local Space → World Space → View Space → Clip Space\n</code></pre>\n<p>(The GPU then automatically handles the final conversion to Screen Space)</p><h3 id=\"core-concepts\">Core Concepts</h3>\n<ul>\n<li><strong>Parallelism</strong>: The GPU’s core strength. It processes thousands of vertices and millions of fragments simultaneously. Your shader code is the instruction set for this parallel work.</li>\n<li><strong>Interpolation</strong>: The process by which the <strong>Rasterizer</strong> automatically and smoothly blends data (like colors, UVs, or normals) that was output by the <strong>Vertex Shader</strong> at the corners of a triangle. This provides a unique value for that data to the <strong>Fragment Shader</strong> for every pixel the triangle covers.</li>\n</ul>\n",
            "image": "https://xav.github.io/media/posts/3/cover.png",
            "author": {
                "name": "Xavier Basty Kjellberg"
            },
            "tags": [
                   "wgsl",
                   "shaders",
                   "rust",
                   "bevy"
            ],
            "date_published": "2025-08-30T22:42:00+02:00",
            "date_modified": "2025-12-13T19:49:03+01:00"
        },
        {
            "id": "https://xav.github.io/learning-wgsl-shaders-with-bevy-016-a-practical-journey/",
            "url": "https://xav.github.io/learning-wgsl-shaders-with-bevy-016-a-practical-journey/",
            "title": "Learning WGSL Shaders with Bevy 0.16: A Practical Journey",
            "summary": "Does This Sound Familiar? You’re a Bevy developer. You love Rust’s power and safety, and you’ve started to feel comfortable building scenes and game logic.",
            "content_html": "<h2 id=\"does-this-sound-familiar\">Does This Sound Familiar?</h2>\n<p>You’re a Bevy developer. You love Rust’s power and safety, and you’ve started to feel comfortable building scenes and game logic. But now you want to create something truly unique - a shimmering shield, a stylized water surface, a custom lighting model - and you realize you need to write a shader.</p><p>So you open a <code>.wgsl</code> file… and you hit a wall.</p><p>You look for tutorials, but they’re almost all for GLSL or Unity, using a different language and a different engine. You look at the official Bevy examples, but they seem to assume you already know how shaders work. You’re stuck in a frustrating gap: you know the engine, you know the language, but you don’t know how to bridge the two to speak directly to the GPU.</p><p><strong>I created this series because I was that developer.</strong></p><p>This is not a theoretical textbook or a high-level overview. It is the practical, step-by-step guide I wish I had when I was starting. It’s the result of systematically navigating that gap, figuring out the fundamentals, hitting the common pitfalls, and documenting what finally made the concepts “click.”</p><p>My goal is to provide a clear, linear path that takes you from the absolute basics of the graphics pipeline all the way to advanced techniques, with every single concept explained and demonstrated inside a working Bevy project. This is the journey of learning how to think in shaders, and I’m thrilled to share it with you.</p><h2 id=\"our-approach-a-practical-incremental-journey\">Our Approach: A Practical, Incremental Journey</h2>\n<p>This is a <strong>practical, hands-on series</strong>. We will learn by building, not just by reading. Every single article is built around a working Bevy project that you can run, modify, and experiment with. Our philosophy is that you don’t truly understand a concept until you’ve seen it work, broken it, and fixed it again.</p><p>Our journey is structured to build your knowledge from the ground up, ensuring you have a solid foundation before moving on to more complex topics. Here’s the path we’ll take:</p><ol>\n<li><p><strong>First, we’ll build the foundation.</strong> We will demystify the <strong>Graphics Pipeline</strong> and learn the fundamental “alphabet” of WGSL - its data types, variables, and functions. You’ll understand where your code runs and the language it speaks.</p></li>\n<li><p><strong>Then, we’ll take control of geometry.</strong> We’ll dive deep into the <strong>Vertex Shader</strong>, where you will learn to manipulate the very shape of your 3D models. You’ll create waving flags, rippling water, and fields of animated grass, learning how to breathe life into static meshes.</p></li>\n<li><p><strong>Next, we’ll learn to paint those shapes with light and color.</strong> We’ll master the <strong>Fragment Shader</strong>, moving beyond simple colors to create procedural patterns, sample textures, and implement our own lighting models. This is where you’ll define the unique visual identity of your projects.</p></li>\n<li><p><strong>Finally, we’ll explore the advanced frontier.</strong> With the fundamentals in place, we’ll unlock the true power of the GPU, exploring post-processing effects, compute shaders, performance optimization, and how to achieve specific artistic styles.</p></li>\n</ol>\n<p>By the end of this series, you won’t just know how to copy and paste shader code - you will have the confidence and the deep understanding to create your own custom rendering effects from scratch.</p><h2 id=\"who-this-series-is-for-and-what-youll-need\">Who This Series Is For (And What You’ll Need)</h2>\n<p>This series is designed for the curious Bevy developer who is ready to take the next step in their creative journey. If you’re comfortable with the basics of Rust and Bevy but feel like the GPU is still a “black box,” you’re in the perfect place.</p><h3 id=\"the-prerequisites\">The Prerequisites</h3>\n<p>This is not a “from zero” programming course. We’ll be moving at a steady pace, and I’ll assume you have a solid footing in the following areas:</p><ul>\n<li><p><strong>A Good Grasp of Rust:</strong> You don’t need to be a systems-level expert, but you should be comfortable with core concepts like structs, traits, ownership, and the module system.</p></li>\n<li><p><strong>Bevy Fundamentals:</strong> You should have worked through the official Bevy book or built a small project. You know what Components, Systems, and Resources are, and you feel comfortable setting up a basic scene.</p></li>\n<li><p><strong>Basic Vector Math Intuition:</strong> You don’t need a math degree, but you should know what a vector is (<code>Vec3</code>) and have a general idea of what operations like adding, subtracting, or normalizing them mean. We’ll review the more complex math (like dot products and matrices) as we need it, focusing on intuition over raw proofs.</p></li>\n</ul>\n<h3 id=\"what-you-dont-need\">What You Don’t Need</h3>\n<p>This is just as important. You <strong>do not</strong> need:</p><ul>\n<li>Any prior shader programming experience (that’s what we’re here to learn!).</li>\n<li>A deep background in low-level graphics APIs like OpenGL, Vulkan, or DirectX.</li>\n<li>To be a math wizard. A willingness to engage with the concepts is far more important than a formal education in linear algebra.</li>\n</ul>\n<p>Our goal is to build up your knowledge from first principles, right here in the Bevy ecosystem.</p><h2 id=\"setting-up-your-development-playground\">Setting Up Your Development Playground</h2>\n<p>A fast, smooth iteration loop is the secret to enjoying shader development. You want to be able to make a small change to your shader code and see the result instantly, without fighting with long compile times. Let’s create a Bevy project specifically configured for this rapid, creative workflow.</p><h3 id=\"recommended-tools\">Recommended Tools</h3>\n<p>While you can use any text editor, this series is written with a specific, highly effective setup in mind:</p><ul>\n<li><ul>\n<li><strong>Editor</strong>: <strong>Visual Studio Code (VS Code)</strong> is strongly recommended. Its rust-analyzer extension provides top-tier support for Rust, and there are excellent extensions that add syntax highlighting for WGSL, making your shader code much easier to read.</li>\n</ul>\n</li>\n<li><p><strong>Graphics Debugger (Optional but Powerful)</strong>: For advanced debugging, a dedicated tool that can capture and inspect a single frame is invaluable. We won’t need this for the early articles, but knowing it exists is important.</p><ul>\n<li><strong>Windows / Linux</strong>: <strong>RenderDoc</strong> is the open-source industry standard.</li>\n<li><strong>macOS</strong>: Apple’s <strong>Metal GPU Debugger and Frame Capture</strong>, which is built directly into <strong>Xcode</strong>, is the essential tool for debugging Metal applications.</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"step-1-install-the-essentials\">Step 1: Install the Essentials</h3>\n<p>First, ensure you have the Rust toolchain installed. If you’re already a Rust developer, you can likely skip this.</p><pre><code class=\"language-bash\"># Install Rust if you don&#39;t have it\ncurl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh\n</code></pre>\n<h3 id=\"step-2-create-the-project-and-configure-cargotoml\">Step 2: Create the Project and Configure <code>Cargo.toml</code></h3>\n<p>Let’s create a new Bevy project that will be our home for this entire series.</p><pre><code class=\"language-bash\">mkdir bevy-shader-journey\ncd bevy-shader-journey\ncargo init\n</code></pre>\n<p>Now, replace the contents of your <code>Cargo.toml</code> file with the following configuration. We’re adding a few key dependencies and settings to optimize our development experience.</p><pre><code class=\"language-toml\">[package]\nname = &quot;bevy-shader-journey&quot;\nversion = &quot;0.1.0&quot;\nedition = &quot;2021&quot; # Sticking with the 2021 edition for maximum compatibility\n\n[dependencies]\n# The core Bevy engine, version 0.16\nbevy = { version = &quot;0.16&quot;, features = [&quot;file_watcher&quot;] }\n# For faster compile times in debug builds, you can enable this feature.\n# It doesn&#39;t work on Windows though :(\n# bevy = { version = &quot;0.16&quot;, features = [&quot;dynamic_linking&quot;, &quot;file_watcher&quot;] }\n\n# Interactive demo selection - makes it easy to jump between examples\ninquire = &quot;0.7&quot;\n\n# An incredibly useful debugging tool we&#39;ll use in later articles\n# to tweak shader values in real-time.\nbevy-inspector-egui = &quot;0.23&quot;\n\n# This section makes our local code compile faster (opt-level = 1)\n# while keeping our dependencies fully optimized (opt-level = 3).\n# It&#39;s a great trick for improving Bevy&#39;s debug build times.\n[profile.dev]\nopt-level = 1\n\n[profile.dev.package.&quot;*&quot;]\nopt-level = 3\n</code></pre>\n<h3 id=\"step-3-create-the-project-directory-structure\">Step 3: Create the Project Directory Structure</h3>\n<p>A good project organization will make life much easier as we add more examples. Create the necessary directories and files with this command:</p><pre><code class=\"language-bash\">mkdir -p assets/shaders src/demos src/materials\n\n# Create the module files\ntouch src/demos/mod.rs\ntouch src/materials/mod.rs\n</code></pre>\n<p>This gives us:</p><ul>\n<li><code>assets/shaders/</code>: Where all our <code>.wgsl</code> shader files will live.</li>\n<li><code>src/demos/</code>: Where each article’s interactive example will go.</li>\n<li><code>src/materials/</code>: Where the Rust “glue” code for our custom materials will go.</li>\n</ul>\n<h3 id=\"step-4-set-up-the-demo-selection-system\">Step 4: Set Up the Demo Selection System</h3>\n<p>Here’s where things get interesting. Instead of creating separate example files or constantly commenting and uncommenting code, we’re going to build a smart demo selection system. This will let you easily run any example from the series with a simple command.</p><p>Replace the contents of <code>src/main.rs</code> with this code:</p><pre><code class=\"language-rust\">mod demos;\nmod materials;\n\nuse std::env;\n\nstruct Demo {\n    number: &amp;&#39;static str,\n    title: &amp;&#39;static str,\n    run: fn(),\n}\n\nimpl Demo {\n    fn matches(&amp;self, query: &amp;str) -&gt; bool {\n        let query_lower = query.to_lowercase();\n        self.number.contains(&amp;query_lower) || self.title.to_lowercase().contains(&amp;query_lower)\n    }\n\n    fn display(&amp;self) -&gt; String {\n        format!(&quot;{} - {}&quot;, self.number, self.title)\n    }\n}\n\nfn main() {\n    // Registry of all available demos\n    let demos = vec![\n        Demo {\n            number: &quot;0.0&quot;,\n            title: &quot;Basic Scene Setup&quot;,\n            run: demos::basic_scene::run,\n        },\n        // More demos will be added as we progress through the series\n    ];\n\n    let args: Vec&lt;String&gt; = env::args().skip(1).collect();\n\n    let demo = if args.is_empty() {\n        select_demo_interactive(&amp;demos)\n    } else {\n        let query = args.join(&quot; &quot;);\n        find_and_select_demo(&amp;demos, &amp;query)\n    };\n\n    match demo {\n        Some(d) =&gt; {\n            println!(&quot;\\n🚀 Running: {}\\n&quot;, d.display());\n            (d.run)();\n        }\n        None =&gt; {\n            println!(&quot;No demo selected. Exiting.&quot;);\n            std::process::exit(0);\n        }\n    }\n}\n\nfn find_and_select_demo&lt;&#39;a&gt;(demos: &amp;&#39;a [Demo], query: &amp;str) -&gt; Option&lt;&amp;&#39;a Demo&gt; {\n    let matches: Vec&lt;&amp;Demo&gt; = demos.iter().filter(|d| d.matches(query)).collect();\n\n    match matches.len() {\n        0 =&gt; {\n            eprintln!(&quot;❌ No demos match &#39;{}&#39;\\n&quot;, query);\n            show_available_demos(demos);\n            println!();\n            select_demo_interactive(demos)\n        }\n        1 =&gt; Some(matches[0]),\n        _ =&gt; {\n            eprintln!(&quot;⚠️  Multiple demos match &#39;{}&#39;:\\n&quot;, query);\n            select_from_list(&amp;matches)\n        }\n    }\n}\n\nfn select_demo_interactive&lt;&#39;a&gt;(demos: &amp;&#39;a [Demo]) -&gt; Option&lt;&amp;&#39;a Demo&gt; {\n    println!(&quot;Available demos:&quot;);\n    show_available_demos(demos);\n    println!();\n\n    let demo_refs: Vec&lt;&amp;Demo&gt; = demos.iter().collect();\n    select_from_list(&amp;demo_refs)\n}\n\nfn show_available_demos(demos: &amp;[Demo]) {\n    for demo in demos {\n        println!(&quot;  • {}&quot;, demo.display());\n    }\n}\n\nfn select_from_list&lt;&#39;a&gt;(demos: &amp;[&amp;&#39;a Demo]) -&gt; Option&lt;&amp;&#39;a Demo&gt; {\n    use inquire::Select;\n\n    let options: Vec&lt;String&gt; = demos.iter().map(|d| d.display()).collect();\n    let selected = Select::new(&quot;Select a demo to run:&quot;, options).prompt();\n\n    match selected {\n        Ok(selected_text) =&gt; demos.iter().find(|d| d.display() == selected_text).copied(),\n        Err(_) =&gt; {\n            println!(&quot;Selection cancelled.&quot;);\n            None\n        }\n    }\n}\n</code></pre>\n<p><strong>What does this do?</strong> This system lets you run any demo from the series with intuitive commands:</p><pre><code class=\"language-rust\"># Run by article number\ncargo run 1.1\n\n# Run by partial title match\ncargo run pipeline\n\n# Multiple matches? You&#39;ll get an interactive menu with arrow keys\ncargo run shader\n\n# No arguments? See all available demos and select with arrow keys\ncargo run\n</code></pre>\n<p>As you progress through the series, you’ll simply add new demos to the <code>demos</code> vector in <code>main.rs</code>, and they’ll automatically be available through this selection system. No managing multiple example files or hunting through code!</p><h3 id=\"step-5-create-your-first-demo-module\">Step 5: Create Your First Demo Module</h3>\n<p>Now let’s create the first demo that we registered in our system. Create <code>src/demos/basic_scene.rs</code>:</p><pre><code class=\"language-rust\">use bevy::prelude::*;\n\npub fn run() {\n    App::new()\n        .add_plugins(DefaultPlugins.set(AssetPlugin {\n            // Enable hot reloading\n            watch_for_changes_override: Some(true),\n            ..default()\n        }))\n        .add_systems(Startup, setup)\n        .add_systems(Update, rotate_camera)\n        .run();\n}\n\nfn setup(\n    mut commands: Commands,\n    mut meshes: ResMut&lt;Assets&lt;Mesh&gt;&gt;,\n    mut materials: ResMut&lt;Assets&lt;StandardMaterial&gt;&gt;,\n) {\n    // Add a simple scene we can apply our shaders to\n    commands.spawn((\n        Mesh3d(meshes.add(Cuboid::new(2.0, 2.0, 2.0))),\n        MeshMaterial3d(materials.add(Color::srgb(0.8, 0.7, 0.6))),\n    ));\n\n    // Light\n    commands.spawn((\n        PointLight {\n            shadows_enabled: true,\n            ..default()\n        },\n        Transform::from_xyz(4.0, 8.0, 4.0),\n    ));\n\n    // Camera\n    commands.spawn((\n        Camera3d::default(),\n        Transform::from_xyz(-2.5, 4.5, 9.0).looking_at(Vec3::ZERO, Vec3::Y),\n    ));\n}\n\n// Simple camera rotation to see our shaders from different angles\nfn rotate_camera(time: Res&lt;Time&gt;, mut camera_query: Query&lt;&amp;mut Transform, With&lt;Camera3d&gt;&gt;) {\n    for mut transform in camera_query.iter_mut() {\n        let radius = 9.0;\n        let angle = time.elapsed_secs() * 0.5;\n        transform.translation.x = angle.cos() * radius;\n        transform.translation.z = angle.sin() * radius;\n        transform.look_at(Vec3::ZERO, Vec3::Y);\n    }\n}\n</code></pre>\n<p>And register it in <code>src/demos/mod.rs</code>:</p><pre><code class=\"language-rust\">pub mod basic_scene;\n</code></pre>\n<p><strong>The pattern you’ll follow for every article:</strong></p><ol>\n<li>Create a new module in <code>src/demos/</code> (e.g., <code>first_shader.rs</code>)</li>\n<li>Implement a <code>pub fn run()</code> function that starts a Bevy app</li>\n<li>Add the module to <code>src/demos/mod.rs</code></li>\n<li>Register it in the <code>demos</code> vector in <code>main.rs</code></li>\n</ol>\n<p>That’s it! The demo selection system handles the rest.</p><h3 id=\"step-5-test-your-setup\">Step 5: Test Your Setup</h3>\n<p>You’re all set! Let’s make sure everything works:</p><p>bash</p><pre><code class=\"language-bash\"># Run the basic scene demo directly\ncargo run 0.0\n\n# Or try the interactive selection\ncargo run\n</code></pre>\n<p>You should see a simple scene with a rotating camera orbiting around a cube.</p><p><strong>Try experimenting with the selection system:</strong></p><pre><code class=\"language-bash\">cargo run basic     # Matches &quot;Basic Scene Setup&quot;\ncargo run scene     # Same result\ncargo run xyz       # No match - shows all demos and lets you select\n</code></pre>\n<p><strong>Congratulations!</strong> You now have a robust development environment with:</p><ul>\n<li>Fast iteration with hot-reloading for shader changes</li>\n<li>An intuitive demo selection system for jumping between examples</li>\n<li>A clean project structure that will scale as you learn</li>\n</ul>\n<p>When you save changes to a shader file in the <code>assets</code> directory, Bevy will automatically detect the change and reload it in real-time. This instant feedback is the key to learning and experimenting with shaders effectively.</p><h2 id=\"understanding-the-project-structure\">Understanding the Project Structure</h2>\n<p>Here’s how everything fits together:</p><pre><code class=\"language-plaintext\">bevy-shader-journey/\n├── assets/\n│   └── shaders/              # Your .wgsl shader files\n│       └── first_shader.wgsl # (We&#39;ll create these as we go)\n├── src/\n│   ├── main.rs               # Demo selection system\n│   ├── demos/                # One module per article\n│   │   ├── mod.rs\n│   │   ├── basic_scene.rs    # Article 0.0\n│   │   └── first_shader.rs   # (Article 1.1, etc.)\n│   └── materials/            # Custom material definitions\n│       └── mod.rs\n└── Cargo.toml\n</code></pre>\n<p><strong>The workflow:</strong></p><ol>\n<li>Read an article to understand the concepts</li>\n<li>Run the demo: <code>cargo run [article-number]</code></li>\n<li>Look at the code in <code>src/demos/[name].rs</code></li>\n<li>Examine the shader in <code>assets/shaders/[name].wgsl</code></li>\n<li>Experiment - change values, break things, see what happens!</li>\n<li>Move to the next article when ready</li>\n</ol>\n<h2 id=\"a-mindset-for-success\">A Mindset for Success</h2>\n<p>You are now ready to begin. As you dive into the world of shaders, keeping a few practical tips in mind will make the learning process smoother and more enjoyable.</p><ul>\n<li><strong>Start Simple, Then Iterate.</strong> The golden rule of shader development. Always begin with the absolute most basic version of an effect that works, even if it’s just a solid color. Once you have a working baseline, add complexity one small step at a time. This makes debugging infinitely easier.</li>\n<li><strong>Embrace the Visual Debugging Loop.</strong> Your primary debugging tool is the screen itself. Is the effect too bright? Multiply by 0.5. Is it upside down? Multiply a coordinate by <code>-1.0</code>. Get comfortable making small, incremental changes and immediately observing the visual result.</li>\n<li><strong>Use Descriptive Variable Names.</strong> Shaders can quickly become a maze of vector math. A variable named <code>surfaceToLightDirection</code> is a thousand times clearer than <code>vecL</code>. Your future self, trying to debug the code, will thank you.</li>\n<li><strong>Save Your Progress Frequently.</strong> Shader development is highly experimental. You’ll often go down a path that leads to a visual mess. Using a version control system like Git to commit frequently after each small success will give you the freedom to experiment without fear of losing your working code.</li>\n<li><strong>Jump Between Examples Freely.</strong> One of the beauties of our demo selection system is that you can easily revisit previous techniques. Forgot how normal mapping works? Just <code>cargo run normal</code> and refresh your memory. Want to compare two approaches? Run them side by side!</li>\n</ul>\n<h2 id=\"lets-get-started\">Let’s Get Started!</h2>\n<p>Your development environment is configured, your mindset is right, and the path is laid out before you. That blank <code>.wgsl</code> file is no longer an intimidating obstacle - it’s a canvas waiting for your creativity.</p><p>The demo selection system gives you the freedom to explore at your own pace, jumping between concepts and building your understanding incrementally. Each article in this series adds a new demo to your toolkit, and by the end, you’ll have a comprehensive library of shader techniques at your fingertips.</p><p>It’s time to dive in and learn how to speak directly to the GPU.</p><p>Next up: [1.1 - Understanding the Graphics Pipeline]</p><hr>\n<h2 id=\"quick-reference\">Quick Reference</h2>\n<p><strong>Running Demos:</strong></p><pre><code class=\"language-bash\">cargo run 1.1              # By article number\ncargo run pipeline         # By keyword\ncargo run                  # Interactive selection\n</code></pre>\n<p><strong>Project Structure:</strong></p><ul>\n<li><code>src/main.rs</code> - Demo selection system</li>\n<li><code>src/demos/</code> - One module per article (each exports <code>pub fn run()</code>)</li>\n<li><code>src/materials/</code> - Custom material definitions</li>\n<li><code>assets/shaders/</code> - WGSL shader files</li>\n</ul>\n<p><strong>Development Tips:</strong></p><ul>\n<li>Save a shader file → Bevy auto-reloads it</li>\n<li>Small changes → Immediate visual feedback</li>\n<li>Commit working code frequently</li>\n<li>Use descriptive names in shader code</li>\n</ul>\n",
            "image": "https://xav.github.io/media/posts/2/cover.png",
            "author": {
                "name": "Xavier Basty Kjellberg"
            },
            "tags": [
                   "wgsl",
                   "shaders",
                   "rust",
                   "bevy"
            ],
            "date_published": "2025-08-29T22:38:00+02:00",
            "date_modified": "2025-12-09T22:39:17+01:00"
        }
    ]
}
